{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation in Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to Model Evaluation**\n",
    "\n",
    "Welcome to the exploration of model evaluation. In regression, our goal is accurate prediction for unknown cases. After building a regression model, evaluation becomes crucial. This video covers two evaluation approaches: \"Train and Test on the Same Dataset\" and \"Train/Test Split.\"\n",
    "\n",
    "**Train and Test on the Same Dataset**\n",
    "\n",
    "*Overview:*\n",
    "- Entire dataset used for training and testing.\n",
    "- A portion of the data is set aside for testing without labels.\n",
    "- Labels (actual values) are used only as ground truth for accuracy comparison.\n",
    "\n",
    "![alt text](image-16.png)\n",
    "\n",
    "*Evaluation Metrics:*\n",
    "- Calculate accuracy by comparing predicted values (y hat) with actual values (y).\n",
    "- Error is the average difference between predicted and actual values.\n",
    "\n",
    "![alt text](image-17.png)\n",
    "\n",
    "*Pros and Cons:*\n",
    "- Simple but may lead to overfitting.\n",
    "- Training accuracy is high, but out-of-sample accuracy is low.\n",
    "\n",
    "![alt text](image-18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/Test Split Approach**\n",
    "\n",
    "*Overview:*\n",
    "- Dataset split into training (e.g., rows 0-5) and testing (e.g., rows 6-9) sets.\n",
    "- Model trained on the training set and tested on the separate testing set, both sets are mutually exclusive.\n",
    "\n",
    "![alt text](image-19.png)\n",
    "\n",
    "*Benefits:*\n",
    "- More realistic evaluation of out-of-sample accuracy.\n",
    "- Avoids overfitting issues seen in the \"Train and Test on the Same Dataset\" approach.\n",
    "\n",
    "![alt text](image-20.png)\n",
    "\n",
    "*Considerations:*\n",
    "- Ensures the model has no prior knowledge of testing set outcomes.\n",
    "- Essential for real-world applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**K-Fold Cross-Validation**\n",
    "\n",
    "*Overview:*\n",
    "- Addresses issues of dependency in previous approaches.\n",
    "- Dataset divided into K folds (e.g., K=4).\n",
    "- Multiple train/test splits performed, and results averaged for consistency.\n",
    "\n",
    "![alt text](image-21.png)\n",
    "\n",
    "*Benefits:*\n",
    "- Mitigates dependency problems seen in other methods.\n",
    "- Provides a more reliable out-of-sample accuracy.\n",
    "\n",
    "*Limitation:*\n",
    "- Detailed exploration of K-Fold Cross-Validation is beyond this course's scope.'ll,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics for Regression\n",
    "\n",
    "**Introduction to Accuracy Metrics**\n",
    "\n",
    "Welcome to the exploration of accuracy metrics for model evaluation in regression. In this video, we will delve into various metrics that play a crucial role in assessing the performance of a regression model.\n",
    "\n",
    "**Understanding Model Evaluation Metrics**\n",
    "\n",
    "*Overview:*\n",
    "- Evaluation metrics are essential for explaining a model's performance.\n",
    "- They provide insights into areas requiring improvement during model development.\n",
    "- The primary focus is on comparing actual values with predicted values to calculate accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Regression Model Evaluation Metrics**\n",
    "\n",
    "*1. Mean Absolute Error (MAE):*\n",
    "- Definition: Mean of the absolute value of errors.\n",
    "- Interpretation: Represents the average error.\n",
    "- Ease of Understanding: Simple and straightforward.\n",
    "\n",
    "*2. Mean Squared Error (MSE):*\n",
    "- Definition: Mean of the squared errors.\n",
    "- Significance: Emphasizes large errors due to the squared term.\n",
    "- Widely Used: More popular than MAE in the data science community (because error terms are squared)\n",
    "\n",
    "*3. Root Mean Squared Error (RMSE):*\n",
    "- Definition: Square root of the mean squared error.\n",
    "- Significance: Interpretable in the same units as the response vector (Y units).\n",
    "- Popularity: Widely used for its ease of interpretation.\n",
    "\n",
    "*4. Relative Absolute Error (RAE):*\n",
    "- Definition: Total absolute error normalized by dividing it by the total absolute error of the simple predictor.\n",
    "- Significance: Provides a relative measure of error.\n",
    "\n",
    "*5. Relative Squared Error (RSE):*\n",
    "- Similar to RAE, adopted widely in the data science community for calculating R-squared.\n",
    "\n",
    "*6. R-squared:*\n",
    "- Definition: Metric for the accuracy of the model.\n",
    "- Significance: Represents how close data values are to the fitted regression line.\n",
    "- Higher R-squared indicates a better fit of the model to the data.\n",
    "\n",
    "![alt text](image-22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "## **Simple Linear Regression vs. Multiple Linear Regression**\n",
    "\n",
    "- *Simple Linear Regression:* Utilizes one independent variable to estimate a dependent variable, e.g., predicting CO₂ emission using engine size.\n",
    "  \n",
    "- *Multiple Linear Regression:* Incorporates multiple independent variables in predicting the dependent variable, e.g., predicting CO₂ emission using engine size and the number of cylinders.\n",
    "\n",
    "**Applications of Multiple Linear Regression**\n",
    "\n",
    "Multiple linear regression is applicable in two scenarios:\n",
    "1. Identifying the strength of effects: Determines the impact of independent variables on the dependent variable.\n",
    "   - Example: Examining the effects of revision time, test anxiety, lecture attendance, and gender on student exam performance.\n",
    "2. Predicting the impact of changes: Understands how the dependent variable changes with alterations in independent variables.\n",
    "   - Example: Predicting how a person's blood pressure changes with variations in body mass index while holding other factors constant.\n",
    "\n",
    "**Understanding Multiple Linear Regression**\n",
    "\n",
    "- Predicts a continuous variable using multiple independent variables.\n",
    "- The target value (Y) is a linear combination of independent variables (X).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Model Representation**\n",
    "\n",
    "The general form of the model:\n",
    "### $\\hat{y}$ = $\\theta_0$ + $\\theta_1$ $x_1$ + $\\theta_2$ $x_2$ + $\\ldots$ + $\\theta_n$ $x_n$\n",
    "\n",
    "In vector form: \n",
    "\n",
    "## $\\hat{y}$ = $ \\theta^T $ X, \n",
    "where $\\theta$ is the parameters vector and $x$ is the feature set vector.\n",
    "\n",
    "\n",
    "![alt text](image-23.png)\n",
    "\n",
    "**Optimizing Parameters in Multiple Linear Regression**\n",
    "\n",
    "- The goal is to minimize the Mean Squared Error (MSE) to achieve the best-fit hyperplane.\n",
    "- MSE is the mean of squared errors, indicating the average discrepancy between predicted and actual values.\n",
    "\n",
    "![alt text](image-24.png)\n",
    "\n",
    "**Parameter Estimation Methods**\n",
    "\n",
    "1. *Ordinary Least Squares:* Minimizes MSE using linear algebra operations. Suitable for smaller datasets (rows < 10,000).\n",
    "2. *Optimization Algorithm (e.g., **Gradient Descent**):* Iteratively minimizes error through coefficient adjustments. Suitable for larger datasets.\n",
    "\n",
    "**Prediction Phase**\n",
    "\n",
    "Once parameters are found, predictions involve solving the linear model equation for a specific set of inputs.\n",
    "\n",
    "Example linear model: $\\hat{y}$ = 125 + 6.2 * `engine_size` + 14 * `cylinders` + $\\ldots$\n",
    "\n",
    "![alt text](image-25.png)\n",
    "\n",
    "**Concerns and Considerations**\n",
    "\n",
    "- **Overfitting:** Adding too many independent variables may lead to overfitting, resulting in a model too specific to the dataset.\n",
    "- **Variable Selection:** The number of independent variables should be chosen judiciously based on theoretical justification rather than using all fields.\n",
    "- **Categorical Variables:** Categorical variables can be incorporated by converting them into numerical variables.\n",
    "\n",
    "**Checking for Linearity**\n",
    "\n",
    "Ensure a linear relationship between the dependent variable and each independent variable using methods like scatter plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
