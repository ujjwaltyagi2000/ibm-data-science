{"cells":[{"cell_type":"markdown","id":"76a04e25-ae4f-4d78-b342-2a0197511ea6","metadata":{},"source":["# **Web Scraping**\n"]},{"cell_type":"markdown","id":"d4d5da7f-e04d-49da-a6a2-1d2406e2426c","metadata":{},"source":["## Introduction to Web scraping\n","\n","Web scraping, also known as web harvesting or web data extraction, is the process of extracting information from websites or web pages. It involves automated retrieval of data from web sources and is commonly used for a wide range of applications such as data analysis, data mining, price comparison, content aggregation, and more.\n","How web scraping works:\n","\n","**HTTP Request:**\n","\n","The process typically begins with an HTTP request. A web scraper sends an HTTP request to a specific URL, similar to how a web browser would when you visit a website. The request is usually an HTTP GET request, which retrieves the content of the web page.\n","\n","**Web Page Retrieval:**\n","\n","The web server hosting the website responds to the request by sending back the requested web page's HTML content. This content includes not only the visible text and media elements but also the underlying HTML structure that defines the page's layout.\n","\n","**HTML Parsing:**\n","\n","Once the HTML content is received, it needs to be parsed. Parsing involves breaking down the HTML structure into its individual components, such as tags, attributes, and text content. This is where a library like BeautifulSoup in Python is commonly used. It creates a structured representation of the HTML content that can be easily navigated and manipulated.\n","\n","**Data Extraction:**\n","\n","With the HTML content parsed, web scrapers can now identify and extract the specific data they need. This data can include text, links, images, tables, product prices, news articles, and more. Scrapers locate the data by searching for relevant HTML tags, attributes, and patterns in the HTML structure.\n","\n","**Data Transformation:**\n","\n","Extracted data may need further processing and transformation. For instance, removing HTML tags from text, converting data formats, or cleaning up messy data. This step ensures that the data is ready for analysis or other use cases.\n","\n","**Storage:**\n","\n","After extraction and transformation, the scraped data can be stored in various formats, such as databases, spreadsheets, or even JSON or CSV files. The choice of storage format depends on the specific project's requirements.\n","\n","**Automation:**\n","\n","In many cases, web scraping is automated using scripts or programs. These automation tools allow for recurring data extraction from multiple web pages or websites. Automated scraping is especially useful for collecting data from dynamic websites that regularly update their content."]},{"cell_type":"markdown","metadata":{},"source":["## Required Tools\n","\n","Web scraping requires Python code and two essential modules: Requests and Beautiful Soup. Ensure you have both modules installed in your Python environment."]},{"cell_type":"code","execution_count":60,"id":"c91808fa-4e9a-43d8-8786-2b55e504fe83","metadata":{},"outputs":[],"source":["from bs4 import BeautifulSoup # this module helps in web scrapping.\n","import requests  # this module helps us to download a web page"]},{"cell_type":"markdown","metadata":{},"source":["## Fetching and Parsing HTML\n","\n","To start web scraping, you need to fetch the HTML content of a webpage and parse it using Beautiful Soup. Here's a step-by-step example:"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<!DOCTYPE html>\n","<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-zebra-design-enabled vector-feature-custom-font-size-clientpref-0 vector-feature-client-preferences-di\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# Specify the URL of the webpage you want to scrape\n","url = 'https://en.wikipedia.org/wiki/IBM'\n","\n","# Send an HTTP GET request to the webpage\n","response = requests.get(url)\n","\n","# Store the HTML content in a variable\n","html_content = response.text\n","\n","# Create a BeautifulSoup object to parse the HTML\n","soup = BeautifulSoup(html_content, 'html.parser')\n","\n","# Display a snippet of the HTML content\n","print(html_content[:500])"]},{"cell_type":"markdown","metadata":{},"source":["## Navigating the HTML Structure\n","\n","BeautifulSoup represents HTML content as a tree-like structure, allowing for easy navigation. You can use methods like find_all to filter and extract specific HTML elements. For example, to find all anchor tags () and print their text:"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Jump to content\n","Main page\n","Contents\n","Current events\n","Random article\n","About Wikipedia\n","Contact us\n","Donate\n","Help\n","Learn to edit\n","Community portal\n","Recent changes\n","Upload file\n","\n","\n","\n","\n","\n","\n","\n","\n","Search\n","\n","Create account\n","Log in\n"," Create account\n"," Log in\n","learn more\n","Contributions\n","Talk\n","\n","(Top)\n","\n","\n","\n","1History\n","\n","\n","\n","2Headquarters and offices\n","\n","\n","\n","3Finance\n","\n","\n","\n","4Products and services\n","\n","\n","\n","5Research\n","\n","\n","\n","6Brand and reputation\n","\n","\n","\n","7People and culture\n","\n","\n","\n","7.1Employees\n","\n","\n","\n","7.1.1IBM alumni\n","\n","\n","\n","7.2Board and shareholders\n","\n","\n","\n","7.3Allegations of Racism\n","\n","\n","\n","8See also\n","\n","\n","\n","9References\n","\n","\n","\n","10Further reading\n","\n","\n","\n","11External links\n","\n","Afrikaans\n","Alemannisch\n","العربية\n","Asturianu\n","Azərbaycanca\n","تۆرکجه\n","বাংলা\n","Bân-lâm-gú\n","Башҡортса\n","Беларуская\n","Беларуская (тарашкевіца)\n","Български\n","Bosanski\n","Català\n","Чӑвашла\n","Čeština\n","Dansk\n","Deutsch\n","Eesti\n","Ελληνικά\n","Español\n","Esperanto\n","Euskara\n","فارسی\n","Français\n","Gaeilge\n","Galego\n","Gĩkũyũ\n","한국어\n","Հայերեն\n","हिन्दी\n","Hrvatski\n","Ido\n","Bahasa Indonesia\n","Interlingue\n","Íslenska\n","Italiano\n","עברית\n","Jawa\n","ಕನ್ನಡ\n","ქართული\n","Қазақша\n","Kiswahili\n","Kurdî\n","Кыргызча\n","Latina\n","Latviešu\n","Lëtzebuergesch\n","Lietuvių\n","Magyar\n","मैथिली\n","Македонски\n","മലയാളം\n","मराठी\n","مصرى\n","Bahasa Melayu\n","Монгол\n","Nederlands\n","नेपाली\n","日本語\n","Norsk bokmål\n","Norsk nynorsk\n","Occitan\n","ଓଡ଼ିଆ\n","Oʻzbekcha / ўзбекча\n","ਪੰਜਾਬੀ\n","پنجابی\n","Piemontèis\n","Polski\n","Português\n","Qaraqalpaqsha\n","Română\n","Runa Simi\n","Русский\n","Саха тыла\n","Scots\n","Shqip\n","සිංහල\n","Simple English\n","Slovenčina\n","Slovenščina\n","کوردی\n","Српски / srpski\n","Srpskohrvatski / српскохрватски\n","Suomi\n","Svenska\n","Tagalog\n","தமிழ்\n","Татарча / tatarça\n","ไทย\n","Тоҷикӣ\n","Türkçe\n","Українська\n","اردو\n","Tiếng Việt\n","Winaray\n","吴语\n","ייִדיש\n","粵語\n","中文\n","Edit links\n","Article\n","Talk\n","Read\n","Edit\n","View history\n","Read\n","Edit\n","View history\n","What links here\n","Related changes\n","Upload file\n","Special pages\n","Permanent link\n","Page information\n","Cite this page\n","Get shortened URL\n","Wikidata item\n","Download as PDF\n","Printable version\n","Wikimedia Commons\n","Wikinews\n","Wikiquote\n","IBM (disambiguation)\n","Big Blue (disambiguation)\n","\n","Paul Rand\n","Trade name\n","Computing-Tabulating-Recording Company\n","Public\n","Traded as\n","NYSE\n","IBM\n","DJIA\n","S&P 100\n","S&P 500\n","ISIN\n","Information technology\n","Bundy Manufacturing Company\n","Computing Scale Company of America\n","International Time Recording Company\n","Tabulating Machine Company\n","Computing-Tabulating-Recording Company\n","Computing-Tabulating-Recording Company\n","Endicott, New York\n","[1]\n","Herman Hollerith\n","Charles Ranlett Flint\n","Thomas J. Watson, Sr.\n","Armonk, New York\n","United States\n","[2]\n","Arvind Krishna\n","[3]\n","Gary Cohn\n","[4]\n","Automation\n","Robotics\n","Artificial intelligence\n","Cloud computing\n","Consulting\n","Blockchain\n","Computer hardware\n","Software\n","Quantum computing\n","IBM Cloud\n","IBM Cognos Analytics\n","IBM Planning Analytics\n","SQL\n","Watson\n","Information Management Software\n","SPSS\n","ILOG\n","Tivoli Software\n","WebSphere\n","alphaWorks\n","Mashup Center\n","PureQuery\n","Fortran\n","IBM Quantum Experience\n","Mainframe\n","Power Systems\n","IBM storage\n","IBM Q System One\n","Full List\n","Outsourcing\n","Professional services\n","Managed services\n","US$\n","[5]\n","Operating income\n","[5]\n","Net income\n","[5]\n","Total assets\n","[5]\n","Total equity\n","[5]\n","[5]\n","Subsidiaries\n","List of subsidiaries\n","www.ibm.com\n","\n","doing business as\n","[6]\n","multinational\n","technology corporation\n","Armonk, New York\n","[7]\n","[8]\n","middleware\n","hosting\n","consulting services\n","mainframe computers\n","nanotechnology\n","[9]\n","[10]\n","[11]\n","Computing-Tabulating-Recording Company\n","holding company\n","punch-card tabulating systems\n","IBM mainframe\n","System/360\n","computing platform\n","[12]\n","multipurpose microcomputer\n","IBM Personal Computer\n","commodity production\n","Lenovo Group\n","supercomputers\n","consistently ranked\n","[12]\n","[13]\n","automated teller machine\n","dynamic random-access memory\n","floppy disk\n","hard disk drive\n","magnetic stripe card\n","relational database\n","SQL programming language\n","UPC barcode\n","[14]\n","publicly traded company\n","Dow Jones Industrial Average\n","world's largest employers\n","[15]\n","[16]\n","[update]\n","Fortune 500\n","[15]\n","[17]\n","edit\n","History of IBM\n","Endicott, New York\n","[18]\n","[8]\n","[19]\n","[20]\n","Herman Hollerith\n","Electric Tabulating Machine\n","[21]\n","Willard Bundy\n","time clock\n","[22]\n","amalgamated\n","Charles Ranlett Flint\n","Computing-Tabulating-Recording Company\n","[1]\n","[23]\n","Binghamton\n","Dayton, Ohio\n","Detroit, Michigan\n","Washington, D.C.\n","Toronto\n","citation needed\n","Thomas J. Watson, Sr.\n","National Cash Register Company\n","John Henry Patterson\n","[24]\n","antitrust\n","[25]\n","[26]\n","[27]\n","[28]\n","THINK\n","[27]\n","[27]\n","[29]\n","[30]\n","\n","NACA\n","IBM type 704\n","Nazis\n","Holocaust\n","[31]\n","[32]\n","[33]\n","Automatic Sequence Controlled Calculator\n","IBM 701\n","IBM 305 RAMAC\n","7000\n","1400\n","artificial intelligence\n","Arthur L. Samuel\n","Poughkeepsie\n","IBM 704\n","FORTRAN\n","SABRE reservation system\n","American Airlines\n","Selectric\n","\n","IBM System/360\n","University of Michigan\n","\n","Saturn V Instrument Unit\n","IBM System/360\n","IBM System/370\n","IBM mainframe\n","mainframe computer\n","OS/VS1\n","MVS\n","CICS\n","[34]\n","Sherman Antitrust Act\n","[35]\n","Forrest Parry\n","magnetic stripe card\n","George J. Laurer\n","Universal Product Code\n","[36]\n","World Bank\n","financial swaps\n","[37]\n","IBM PC\n","[38]\n","[39]\n","AdStar\n","Lexmark\n","[40]\n","Clayton & Dubilier\n","leveraged buyout\n","[41]\n","[42]\n","[43]\n","[44]\n","[45]\n","Ambra Computer Corporation\n","clone\n","PowerPC\n","workstations\n","[46]\n","[47]\n","[48]\n","Lou Gerstner\n","RJR Nabisco\n","[49]\n","PwC\n","PwC\n","IBM Global Services\n","[50]\n","[51]\n","\n","hard-disk drive\n","DRAM\n","UPC bar code\n","magnetic stripe card\n","[52]\n","Compaq\n","Dell\n","[53]\n","[54]\n","LG\n","South Korean\n","[55]\n","[56]\n","[57]\n","[58]\n","Xnote\n","[59]\n","sold all of its personal computer business\n","Lenovo\n","[60]\n","SPSS Inc.\n","Blue Gene\n","National Medal of Technology and Innovation\n","Barack Obama\n","Watson\n","Jeopardy!\n","Kenexa\n","[61]\n","web hosting service\n","[62]\n","Davao City\n","[63]\n","x86\n","[64]\n","Power ISA\n","Apple Inc.\n","[65]\n","[66]\n","[67]\n","[68]\n","Tencent\n","[69]\n","Cisco\n","[70]\n","UnderArmour\n","[71]\n","Box\n","[72]\n","Microsoft\n","[73]\n","VMware\n","[74]\n","CSC\n","[75]\n","Macy's\n","[76]\n","Sesame Workshop\n","[77]\n","Sesame Street\n","Salesforce.com\n","[78]\n","[79]\n","Cleversafe\n","The Weather Company\n","Weather.com\n","[80]\n","[81]\n","A Boy and His Atom\n","Ustream\n","[82]\n","[83]\n","[84]\n","Groupon\n","[85]\n","The Weather Company\n","[86]\n","Red Hat\n","[87]\n","[88]\n","[89]\n","[90]\n","[91]\n","Kyndryl\n","[92]\n","[93]\n","[94]\n","[95]\n","[96]\n","[97]\n","[98]\n","[99]\n","Russian invasion of Ukraine\n","[100]\n","[101]\n","[102]\n","[103]\n","[104]\n","Software AG\n","webMethods\n","[105]\n","edit\n","\n","Armonk, New York\n","\n","Armonk, New York\n","[106]\n","[107]\n","[108]\n","[109]\n","[110]\n","[update]\n","[2]\n","IBM Watson\n","Astor Place\n","Austin, Texas\n","Research Triangle Park (Raleigh-Durham), North Carolina\n","Rochester, Minnesota\n","Silicon Valley, California\n","1250 René-Lévesque\n","One Atlantic Center\n","Pangu Plaza\n","[111]\n","Beijing National Stadium (\"Bird's Nest\")\n","2008 Summer Olympics\n","IBM India Private Limited\n","Bangalore\n","Coimbatore\n","Chennai\n","Kochi\n","Ahmedabad\n","Delhi\n","Kolkata\n","Mumbai\n","Pune\n","Gurugram\n","Noida\n","Bhubaneshwar\n","Surat\n","Visakhapatnam\n","Hyderabad\n","Bangalore\n","Jamshedpur\n","IBM Rome Software Lab\n","Hursley House\n","330 North Wabash\n","Cambridge Scientific Center\n","IBM Toronto Software Lab\n","IBM Building (Seattle)\n","IBM Hakozaki Facility\n","IBM Yamato Facility\n","IBM Canada Head Office Building\n","[112]\n","IBM Somers Office Complex\n","Spango Valley\n","Tour Descartes\n","Marcel Breuer\n","Eero Saarinen\n","Ludwig Mies van der Rohe\n","I.M. Pei\n","Ricardo Legorreta\n","Honor Award\n","National Building Museum\n","[113]\n","United States Environmental Protection Agency\n","Fortune 500\n","commuter\n","[114]\n","Endicott, New York\n","[115]\n","[116]\n","edit\n","Kyndryl\n","[117]\n","[118]\n","Fortune 500\n","[119]\n","[120]\n","[121]\n","[122]\n","edit\n","List of IBM products\n","\n","Blue Gene\n","National Medal of Technology and Innovation\n","[update]\n","cloud computing\n","analytics\n","Internet of things\n","[123]\n","IT infrastructure\n","mobile\n","[124]\n","cybersecurity\n","[125]\n","IBM Cloud\n","infrastructure as a service\n","software as a service\n","platform as a service\n","cloud delivery models\n","Bluemix\n","SoftLayer\n","dedicated server\n","managed hosting\n","cloud computing\n","[126]\n","cryptographic splitting\n","[127]\n","[128]\n","Hardware\n","Power microprocessors\n","Xbox 360\n","[129]\n","PlayStation 3\n","Nintendo\n","Wii U\n","[130]\n","[131]\n","Secure Blue\n","[132]\n","TrueNorth\n","neuromorphic\n","CMOS\n","integrated circuit\n","[133]\n","all-flash arrays\n","[134]\n","IT outsourcing\n","data centers\n","[135]\n","IBM Developer\n","SPSS\n","statistical analysis\n","Kenexa\n","retention\n","buzzword\n","BrassRing\n","[136]\n","The Weather Company\n","weather.com\n","Weather Underground\n","[137]\n","Smarter Planet\n","sustainable development\n","[138]\n","[139]\n","smart grids\n","[140]\n","water management\n","[141]\n","[142]\n","[143]\n","developerWorks\n","software developers\n","[144]\n","IBM Watson\n","natural language processing\n","unstructured data\n","[145]\n","Jeopardy!\n","Ken Jennings\n","Brad Rutter\n","Memorial Sloan Kettering Cancer Center\n","oncology\n","melanoma\n","[146]\n","[147]\n","\n","IBM Q System One\n","IBM Q System One\n","[148]\n","New York City Police Department\n","IBM Cognos Analytics\n","CompStat\n","[149]\n","[150]\n","[151]\n","[152]\n","Amazon Web Services\n","[153]\n","[154]\n","Lexmark\n","ThinkPad\n","ThinkCentre\n","Lenovo\n","fabless\n","semiconductors\n","GlobalFoundries\n","Kyndryl\n","[155]\n","[156]\n","Turbonomic\n","[157]\n","Watson Health\n","Francisco Partners\n","[158]\n","Rapidus\n","[159]\n","[160]\n","edit\n","\n","Thomas J. Watson Research Center\n","Yorktown Heights, New York\n","\n","IBM Fellow\n","Benoit Mandelbrot\n","fractal geometry\n","Columbia University\n","IBM Research\n","[161]\n","Thomas J. Watson Research Center\n","Almaden lab\n","Australia lab\n","Brazil lab\n","Haifa lab\n","Bangalore\n","Tokyo lab\n","Zurichlab\n","Nairobi\n","R&D\n","[162]\n","Watson\n","[163]\n","Open Source Initiative\n","Linux\n","[164]\n","Linux Technology Center\n","Linux kernel\n","[165]\n","open-source licenses\n","platform-independent\n","software framework\n","Eclipse\n","[166]\n","ICU\n","Java\n","relational database management system\n","Apache Derby\n","open source\n","SCO v. IBM\n","inventions\n","automated teller machine (ATM)\n","dynamic random access memory (DRAM)\n","electronic keypunch\n","financial swap\n","floppy disk\n","hard disk drive\n","magnetic stripe card\n","relational database\n","RISC\n","SABRE airline reservation system\n","SQL\n","Universal Product Code (UPC)\n","virtual machine\n","scanning tunneling microscope\n","individual xenon atoms\n","[167]\n","patents\n","patents\n","[9]\n","Leo Esaki\n","Gerd Binnig\n","Heinrich Rohrer\n","scanning tunneling microscope\n","[168]\n","Georg Bednorz\n","Alex Müller\n","superconductivity\n","Turing Award\n","Frances E. Allen\n","[169]\n","National Medals of Technology (USA)\n","National Medals of Science (USA)\n","edit\n","\n","John F. Kennedy International Airport\n","[170]\n","[171]\n","dress code\n","[170]\n","[172]\n","graphic designer\n","Paul Rand\n","[173]\n","Helvetica\n","IBM Plex\n","Masters Tournament\n","major championships\n","iPhone\n","[174]\n","Ginni Rometty\n","Augusta National Golf Club\n","[175]\n","U.S. Open\n","Wimbledon\n","[176]\n","Olympic Games\n","[177]\n","National Football League\n","[178]\n","[179]\n","Fortune\n","green company\n","Newsweek\n","[180]\n","Barron's\n","[181]\n","Fortune\n","Fast Company\n","technology consulting\n","Vault\n","[182]\n","[183]\n","Drucker Institute\n","[184]\n","2022 Russian invasion of Ukraine\n","Polish Humanitarian Action\n","People in Need\n","[185]\n","ESG\n","CO2e emissions\n","[186]\n","[187]\n","edit\n","edit\n","List of IBM CEOs\n","\n","\n","IBM Watson\n","Jeopardy!\n","group life insurance\n","Thomas J. Watson, Jr.\n","Brown vs. Board of Education\n","Civil Rights Act of 1964\n","Human Rights Campaign\n","[188]\n","health benefits\n","genetic information\n","Working Mother\n","[189]\n","human resources\n","[190]\n","humanitarian work\n","[191]\n","interns\n","Extreme Blue\n","[192]\n","[193]\n","Master Inventor\n","IBM Fellow\n","[194]\n","Louis V. Gerstner Jr.\n","[195]\n","[196]\n","[197]\n","[198]\n","[199]\n","[200]\n","American football\n","X-League\n","Big Blue\n","[201]\n","Mac\n","PC\n","Linux distribution\n","[202]\n","[203]\n","edit\n","Apple Inc.\n","Tim Cook\n","[204]\n","EDS\n","Ross Perot\n","Microsoft\n","John W. Thompson\n","SAP\n","Hasso Plattner\n","Gartner\n","Gideon Gartner\n","Advanced Micro Devices (AMD)\n","Lisa Su\n","[205]\n","Cadence Design Systems\n","Anirudh Devgan\n","[206]\n","Citizens Financial Group\n","Ellen Alemany\n","Yahoo!\n","Alfred Amoroso\n","AT&T\n","C. Michael Armstrong\n","Xerox Corporation\n","David T. Kearns\n","G. Richard Thoman\n","[207]\n","Fair Isaac Corporation\n","Mark N. Greene\n","[208]\n","Citrix Systems\n","Ed Iacobucci\n","Lenovo\n","Steve Ward\n","Teradata\n","Kenneth Simonds\n","Patricia Roberts Harris\n","United States Secretary of Housing and Urban Development\n","[209]\n","Samuel K. Skinner\n","U.S. Secretary of Transportation\n","White House Chief of Staff\n","Mack Mattingly\n","Thom Tillis\n","Scott Walker\n","[210]\n","Arthur K. Watson\n","Todd Akin\n","[211]\n","Glenn Andrews\n","Robert Garcia\n","Katherine Harris\n","[212]\n","Amo Houghton\n","Jim Ross Lightfoot\n","Thomas J. Manton\n","Donald W. Riegle Jr.\n","Ed Zschau\n","NASA\n","Michael J. Massimino\n","Canadian astronaut\n","Governor General\n","Julie Payette\n","Dave Matthews\n","[213]\n","Harvey Mudd College\n","Maria Klawe\n","Western Governors University\n","Robert Mendenhall\n","University of Kentucky\n","Lee T. Todd Jr.\n","NFL\n","Bill Carollo\n","[214]\n","Rangers F.C.\n","John McClelland\n","Nobel Prize in Literature\n","J. M. Coetzee\n","edit\n","Anthem\n","Dow Chemical\n","Johnson and Johnson\n","Royal Dutch Shell\n","UPS\n","Vanguard\n","Cornell University\n","U.S. Navy admiral\n","[215]\n","Warren Buffett\n","holding company\n","Berkshire Hathaway\n","[216]\n","[217]\n","edit\n","[218]\n","edit\n","Companies portal\n","IBM SkillsBuild\n","List of electronics brands\n","List of largest Internet companies\n","List of largest manufacturing companies by revenue\n","Tech companies in the New York City metropolitan region\n","Top 100 US Federal Contractors\n","edit\n","a\n","b\n","Appendix to Hearings Before the Committee on Patents, House of Representatives, Seventy-Fourth Congress, on H. R. 4523, Part III\n","archived\n","a\n","b\n","\"IBM Is Blowing Up Its Annual Performance Review\"\n","Archived\n","^\n","\"IBM – Arvind Krishna – Chief Executive Officer\"\n","Archived\n","^\n","\"IBM Newsroom - Gary Cohn\"\n","a\n","b\n","c\n","d\n","e\n","f\n","\"IBM Reports 2022 Fourth-Quarter and Full-Year Results\"\n","Archived\n","^\n","\"IBM100 - The Making of International Business Machines\"\n","^\n","\"Trust and responsibility. Earned and practiced daily\"\n","a\n","b\n","\"10-K\"\n","Archived\n","a\n","b\n","\"Top Patent Holders of 2020\"\n","Archived\n","^\n","\"2021 Top 50 US Patent Assignees\"\n","^\n","\"Why IBM is no longer interested in breaking patent records–and how it plans to measure innovation in the age of open source and quantum computing\"\n","Archived\n","a\n","b\n","\"IBM | Founding, History, & Products | Britannica\"\n","^\n","\"IBM Tops U.S. Patent List for 28th Consecutive Year with Innovations in Artificial Intelligence, Hybrid Cloud, Quantum Computing and Cyber-Security\"\n","^\n","\"About us\"\n","a\n","b\n","\"Fortune 500\"\n","^\n","Schofield, Jack\n","\"IBM shows growth after 22 straight quarters of declining revenues, but has it turned the corner?\"\n","the original\n","^\n","\"IBM Brand Ranking | All Brand Rankings where IBM is listed!\"\n","^\n","ISBN\n","0-7385-3700-4\n","^\n","Images of America: IBM in Endicott\n","Arcadia Publishing\n","ISBN\n","0-7385-3700-4\n","Archived\n","^\n","\"Dey dial recorder, early 20th century\"\n","Archived\n","^\n","\"Hollerith 1890 Census Tabulator\"\n","Columbia University\n","Archived\n","^\n","\"Employee Punch Clocks\"\n","the original\n","^\n","\"Tabulating Concerns Unite: Flint & Co. Bring Four Together with $19,000,000 capital\"\n","Archived\n","^\n","The Lengthening Shadow: The Life of Thomas J. Watson\n","89–93\n","^\n","ISBN\n","978-1-000-87875-2\n","^\n","a\n","b\n","c\n","\"Chronological History of IBM, 1910s\"\n","Archived\n","^\n","Wherever Men Trade: The Romance of the Cash Register\n","ISBN\n","9780405047138\n","OCLC\n","243101\n","^\n","^\n","^\n","ISBN\n","9780914153108\n","^\n","ISBN\n","978-1-4594-0987-3\n","^\n","\"\"Stranger than Science Fiction: Edwin Black, IBM, and the Holocaust.\"\"\n","Johns Hopkins University Press\n","JSTOR\n","25147861\n","^\n","Campbell-Kelly, Martin\n","MIT Press\n","^\n","\"Monopolization: Corporate Strategy, the IBM Cases, and the Transformation of the Law\"\n","Texas Law Review\n","Archived\n","^\n","\"The history of the UPC bar code and how the bar code symbol and system became a world standard\"\n","Archived\n","^\n","McGraw Hill\n","^\n","\"'Break Up IBM,' Cry Some Investors Who See Value in Those Baby Blues\"\n","^\n","\"Big Blue still breaking up its bureaucracy\"\n","^\n","\"Facts, Figures on IBM's 13 Decentralized Firms\"\n","^\n","\"The Executive Computer; Can I.B.M. Learn From a Unit It Freed?\"\n","^\n","\"IBM Plans Division For Its PC Business; One Executive Expected to Be Put in Control\"\n","the original\n","^\n","\"With New Approach and Executive Team, IBM Seeks a Rebirth\"\n","the original\n","^\n","\"IBM to Unveil New Structure of PC Business\"\n","^\n","\"IBM reports record loss of $8 billion\"\n","^\n","\"I.B.M. and Dell Stake Out the Little Picture in PC's\"\n","the original\n","^\n","\"IBM Power Personal Systems group to be folded into PC Co\"\n","^\n","\"Life science: Fade or flourish ?\"\n","the original\n","^\n","\"IBM Archives: Louis V. Gerstner, Jr\"\n","Archived\n","^\n","\"IBM to acquire PwC Consulting for $3.5 billion\"\n","^\n","\"IBM grabs consulting giant for $3.5 billion\"\n","^\n","\"Not Your Father's PC Company Anymore\"\n","^\n","\"The Strategy For I.B.M.: Loss-Leader PC Sales\"\n","ISSN\n","0362-4331\n","^\n","\"Big Blue to combine PC division with PSG\"\n","^\n","\"IBM, LG Electronics Call Halt To PC Joint Venture in Korea\"\n","The Wall Street Journal\n","ISSN\n","0099-9660\n","^\n","\"LG, IBM to split by end of year\"\n","Korea JoongAng Daily\n","^\n","\"IBM, LG Electronics to End Joint Venture\"\n","Forbes\n","the original\n","^\n","Vance, Ashlee\n","\"South Korea slams IBM with server slush fund charges\"\n","^\n","\"Laptop Retrospective\"\n","^\n","\"Lenovo Completes Acquisition Of IBM's Personal Computing Division\"\n","Archived\n","^\n","\"IBM Plans to Acquire Texas Memory Systems\"\n","Archived\n","^\n","\"IBM to buy website hosting service SoftLayer\"\n","Archived\n","^\n","\"Inside the Video Surveillance Program IBM Built for Philippine Strongman Rodrigo Duterte\"\n","Archived\n","^\n","\"Lenovo says $2.1 billion IBM x86 server deal to close on Wednesday\"\n","Archived\n","^\n","\"Apple + IBM\"\n","Archived\n","^\n","\"Apple Teams Up With IBM For Huge, Expansive Enterprise Push\"\n","Archived\n","^\n","\"Landmark IBM Twitter partnership to help businesses make decisions\"\n","Archived\n","^\n","\"IBM Announces Marketing Partnership With Facebook\"\n","Archived\n","^\n","\"Tencent teams up with IBM to offer business software over the cloud\"\n","Archived\n","^\n","\"Cisco and IBM's New Partnership Is a Lot About Talk\"\n","Archived\n","^\n","\"IBM, Under Armour Team Up To Bring Cognitive Computing To Fitness Apps\"\n","Archived\n","^\n","\"IBM, Box Cloud Partnership: What It Means\"\n","Archived\n","^\n","\"Microsoft just made a deal with IBM – and Apple should be nervous\"\n","Archived\n","^\n","\"VMware and SugarCRM expand partnerships with IBM, make services available on IBM Cloud\"\n","Archived\n","^\n","\"IBM, CSC Expand Their Cloud Deal to the Mainframe\"\n","^\n","\"Macy's Taps IBM, Satisfi for In-Store Shopping Companion\"\n","^\n","\"Sesame Workshop, IBM partner to use Watson for preschoolers\"\n","Archived\n","^\n","\"IBM, Salesforce Strike Global Partnership on Cloud, AI\"\n","Archived\n","^\n","\"IBM Buys Merge Healthcare to Boost Watson Health Cloud\"\n","Archived\n","^\n","\"IBM Agrees to Acquire Weather Channel's Digital Assets\"\n","Archived\n","^\n","\"IBM to Acquire the Weather Company\"\n","Archived\n","^\n","\"IBM acquires Ustream, launches cloud video unit\"\n","Archived\n","^\n","\"IBM Acquires Ustream: Behind the Acquisition\"\n","Archived\n","^\n","\"Big Blue isn't so big anymore\"\n","Archived\n","^\n","\"Groupon sues 'once-great' IBM over patent\"\n","Archived\n","^\n","\"IBM Buys Digital Part of The Weather Company\"\n","Archived\n","^\n","\"IBM to Acquire Red Hat for About $33 Billion\"\n","The Wall Street Journal\n","ISSN\n","0099-9660\n","Archived\n","^\n","\"IBM to Acquire Linux Distributor Red Hat for $33.4 Billion\"\n","Archived\n","^\n","\"IBM to acquire Red Hat, completely changing the cloud landscape and becoming world's #1 hybrid cloud provider\"\n","Archived\n","^\n","\"IBM Closes Landmark Acquisition of Red Hat for $34 Billion; Defines Open, Hybrid Cloud Future\"\n","Archived\n","^\n","\"IBM To Accelerate Hybrid Cloud Growth Strategy And Execute Spin-Off Of Market-Leading Managed Infrastructure Services Unit\"\n","Archived\n","^\n","\"IBM to break up 109-year old company to focus on cloud growth\"\n","Archived\n","^\n","\"IBM spins off a quarter of the company to focus on the cloud\"\n","Archived\n","^\n","\"IBM shares rise on plans to spin off its IT infrastructure unit and focus on the cloud business\"\n","Archived\n","^\n","\"IBM to Spin Off Services Unit to Accelerate Cloud-Computing Pivot\"\n","Archived\n","^\n","\"IBM Splits Into Two Companies\"\n","Archived\n","^\n","\"IBM Spinning Off Infrastructure Managed Services Group To Focus On Cloud Is A Good Move\"\n","Archived\n","^\n","\"IBM names Martin Schroeter as CEO of $19B NewCo services spinoff\"\n","Archived\n","^\n","\"IBM names former financial chief Martin Schroeter as head of new IT infrastructure services company\"\n","ETCIO\n","Reuters\n","Archived\n","^\n","\"Update on Our Actions: War in Ukraine\"\n","^\n","\"IBM finally shutters Russian operations, lays off staff\"\n","^\n","\"IBM Extends Watson.x Governance & Compliance with Manta Acquisition\"\n","^\n","\"IBM suspends ads on X after corporate ads appeared next to pro-Nazi content\"\n","^\n","\"Advertisers Push Back at Social Media Firms over Antisemitism\"\n","^\n","\"IBM to buy Software AG's enterprise integration platforms for $2.3 billion\"\n","^\n","\"Contact Us\"\n","Archived\n","^\n","\"Dominance Ended, I.B.M. Fights Back\"\n","Archived\n","^\n","\"IBM's New Headquarters Reflects A Change in Corporate Style\"\n","The New York Times\n","Archived\n","^\n","\"On the Dedication of the Louis V. Gerstner, Jr., Center for Learning – THINK Blog\"\n","Archived\n","^\n","\"Property Overview\"\n","the original\n","^\n","\"Company Overview of IBM China Company Limited\"\n","Archived\n","^\n","\"Watson IoT Headquarters\"\n","Archived\n","^\n","The Washington Post\n","^\n","\"Environmental Protection\"\n","Archived\n","^\n","\"Village of Endicott Environmental Investigations\"\n","Archived\n","^\n","\"In an I.B.M. Village, Pollution Fears Taint Relations With Neighbors\"\n","Archived\n","^\n","\"IBM earnings and revenue continue to shrink, stock falls 6%\"\n","Archived\n","^\n","\"IBM Market Cap 2006–2021 | IBM\"\n","Archived\n","^\n","\"Fortune 500\"\n","Archived\n","^\n","\"The Truth About IBM's Buybacks\"\n","Archived\n","^\n","\"IBM and the financial engineering economy: James Saft\"\n","Archived\n","^\n","\"Boring IBM Just Got a Lot More Interesting\"\n","Archived\n","^\n","\"IBM Investing $3B in Internet of Things\"\n","Archived\n","^\n","\"Digital workplace services\"\n","Archived\n","^\n","\"IBM Products\"\n","Archived\n","^\n","\"Data Center Knowledge – SoftLayer: $78 Million in First Quarter Revenue\"\n","Archived\n","^\n","\"Cloud computing news: Security\"\n","Archived\n","^\n","\"IBM Inks VMware, GitHub, Bitly Deals, Expands Apple Swift Use As It Doubles Down On The Cloud\"\n","Archived\n","^\n","\"IBM delivers Power-based chip for Microsoft Xbox 360 worldwide launch\"\n","Archived\n","^\n","\"IBM microprocessors drive the new Nintendo WiiU console\"\n","Archived\n","^\n","\"IBM's 45nm SOI microprocessors at core of Nintendo Wii U\"\n","the original\n","^\n","\"Building a smarter planet\"\n","Archived\n","^\n","\"New research initiative sees IBM commit $3 bn\"\n","the original\n","^\n","\"IBM launches flash arrays for smaller enterprises, aims to court EMC, Dell customers\"\n","Archived\n","^\n","\"IBM. Global locations for your global business\"\n","Archived\n","^\n","\"Kenexa Corporation | Company Profile from Hoover's\"\n","Archived\n","^\n","\"IBM to Acquire the Weather Company\"\n","Archived\n","^\n","\"Big Blue's Smarter Marketing Playbook\"\n","Archived\n","^\n","\"At IBM Research, a constant quest for the bleeding edge\"\n","dead link\n","^\n","\"Smart Grid\"\n","the original\n","^\n","\"Smarter Water Management\"\n","the original\n","^\n","\"Smart traffic\"\n","the original\n","^\n","\"Smarter Buildings\"\n","the original\n","^\n","\"About developerWorks\"\n","IBM developerWorks\n","Archived\n","^\n","\"What is Watson?\"\n","Archived\n","^\n","\"Watson Oncology\"\n","the original\n","^\n","\"IBM's Watson Now A Customer Service Agent, Coming To Smartphones Soon\"\n","Archived\n","^\n","\"IBM Unveils Q System One Quantum Computer\"\n","Archived\n","^\n","\"NYPD changes the crime control equation by transforming the way it uses information\"\n","Archived\n","^\n","\"IBM to build Europe's first quantum computer in Germany\"\n","Archived\n","^\n","\"IBM Policy\"\n","^\n","\"IBM exits facial recognition business, calls for police reform\"\n","^\n","\"IBM steps up its cloud partnership strategy with AWS deal\"\n","^\n","\"How Quantum Computing Will Transform Our World\"\n","^\n","\"IBM to Spin off $19B Business to Focus on Cloud Computing\"\n","^\n","\"IBM to name infrastructure services business 'Kyndryl' after spinoff\"\n","Archived\n","^\n","\"IBM to Acquire Software Provider Turbonomic for Over $1.5 Billion\"\n","Archived\n","^\n","\"IBM sells Watson Health assets to investment firm Francisco Partners\"\n","ZDNet\n","Archived\n","^\n","\"IBM and Rapidus Form Strategic Partnership to Build Advanced Semiconductor Technology and Ecosystem in Japan\"\n","^\n","\"GlobalFoundries sues IBM, says trade secrets were unlawfully given to Japan's Rapidus\"\n","^\n","\"IBM Research: Global labs\"\n","Archived\n","^\n","\"IBM's expenditure on research and development from 2005 to 2015 (in billion U.S. dollars)\"\n","Archived\n","^\n","\"Ginni Rometty just set a big goal for IBM: spending $4 billion to bring in $40 billion\"\n","Archived\n","^\n","\"IBM launches biggest Linux lineup ever\"\n","the original\n","^\n","\"IBM invests in Brazil Linux Tech Center\"\n","LWN.net\n","Archived\n","^\n","\"Interview: The Eclipse code donation\"\n","the original\n","^\n","\"IBM Archives: \"IBM\" atoms\"\n","Archived\n","^\n","\"The Nobel Prize in Physics 1986 – Press Release\"\n","Archived\n","^\n","Communications of the ACM\n","doi\n","10.1145/1866739.1866752\n","S2CID\n","11847872\n","a\n","b\n","Postphenomenology: A Critical Companion to Ihde\n","State University of New York Press\n","ISBN\n","0-7914-6787-2\n","Archived\n","^\n","Logos, Letterheads & Business Cards: Design for Profit\n","ISBN\n","2-88046-750-0\n","permanent dead link\n","^\n","The Essential Guide to Computing: The Story of Information Technology\n","55\n","ISBN\n","0-13-019469-7\n","^\n","\"IBM Archives\"\n","Archived\n","^\n","\"IBM and Masters Celebrate 20 Years\"\n","Archived\n","^\n","\"IBM CEO Ginni Rometty is Augusta National's third female member\"\n","Archived\n","^\n","\"Why IBM dominates the U.S. Open\"\n","Archived\n","^\n","\"IBM, Olympics Part Ways After 40 Years\"\n","Archived\n","^\n","\"IBM Ends Its NFL Sponsorship Over Difference in Views\"\n","Archived\n","^\n","\"Best Global Brands Ranking for 2012\"\n","the original\n","^\n","\"IBM #1 in Green Rankingss for 2012\"\n","Archived\n","^\n","\"The World's Most Respected Companies\"\n","Archived\n","^\n","\"Tech Consulting Firm Rankings 2012: Best Firms in Each Practice Area\"\n","the original\n","^\n","\"The World's Most Valuable Brands\"\n","Forbes\n","the original\n","^\n","\"The Best-Managed Companies of 2020—and How They Got That Way\"\n","Archived\n","^\n","\"Tech companies increase donations to Ukraine\"\n","^\n","\"IBM's ESG Datasheet for 2020Q4\"\n","the original\n","Alt URL\n","Archived\n","Wayback Machine\n","^\n","\"IBM Commits To Net Zero Greenhouse Gas Emissions By 2030\"\n","^\n","\"International Business Machines Corp. (IBM) profile\"\n","permanent dead link\n","^\n","\"IBM\"\n","Archived\n","^\n","\"The IBM Corporate Service Corps\"\n","Archived\n","^\n","\"Why IBM Gives Top Employees a Month to Do Service Abroad\"\n","Archived\n","^\n","\"Extreme Blue web page\"\n","Archived\n","^\n","\"IBM Launches Distinguished Designer Program\"\n","^\n","Strategic Marketing Communications: New Ways to Build and Integrate Communications\n","ISBN\n","0-7494-2918-6\n","Archived\n","^\n","\"IBM Attire\"\n","Archived\n","^\n","\"IBM stands for 'I've Been Moved'\"\n","Archived\n","^\n","\"IBM stands for \"I'm by myself' for teleworkers of the blue giant\"\n","Archived\n","^\n","Intelligent Mentoring\n","ISBN\n","9780137009497\n","Archived\n","^\n","\"The Union Avoidance Industry in the United States\"\n","doi\n","10.1111/j.1467-8543.2006.00518.x\n","S2CID\n","155066215\n","the original\n","^\n","\"IBM Global Unions Links\"\n","the original\n","^\n","\"In Japan, IBM employees have formed a football team complete with pro stadium, cheerleaders and televised games\"\n","Archived\n","^\n","\"Switch to Macs from PCs reportedly saves IBM $270 per user\"\n","the original\n","^\n","\"After overhauling its performance review system, IBM now uses an app to give and receive real-time feedback\"\n","Archived\n","^\n","\"Tim Cook\"\n","^\n","\"Executive Biographies – Lisa Su\"\n","Archived\n","^\n","\"Leadership Team\"\n","Archived\n","^\n","^\n","\"Fair Isaac CEO: FICO criticism isn't 'fair'\"\n","Archived\n","^\n","DeLaat, Jacqueline\n","Women in World History, Vol. 7: Harr-I\n","ISBN\n","0-7876-4066-2\n","^\n","\"Wisconsin Gov. Scott Walker: A 2016 Contender But Not A College Graduate\"\n","Archived\n","^\n","\"Official Manual of the State of Missouri, 1993–1994\"\n","permanent dead link\n","^\n","\"Katherine Harris' Biography\"\n","Project Vote Smart\n","Archived\n","^\n","\"New York Times (May 31, 1998)\"\n","The New York Times\n","Archived\n","^\n","\"Board of Directors — Officers\"\n","the original\n","^\n","\"Board of Directors\"\n","Archived\n","^\n","\"Warren Buffett never liked tech stocks. So why does he own Apple?\"\n","The Washington Post\n","Archived\n","^\n","\"Warren Buffett says Berkshire Hathaway has sold completely out of IBM\"\n","Archived\n","^\n","\"We should be ending racism in America, not substituting one form for another!\"\n","edit\n","History of IBM § Further reading\n","ISBN\n","9780709938286\n","Oxford University Press\n","Black, Edwin\n","IBM and the Holocaust: The Strategic Alliance Between Nazi Germany and America's Most Powerful Corporation\n","ISBN\n","0-914153-10-2\n","Big Blues: The Unmaking of IBM\n","ISBN\n","9780517591970\n","Gerstner, Louis V. Jr.\n","ISBN\n","0-00-715448-8\n","ISBN\n","978-0-9833734-6-9\n","ISBN\n","978-0-8166-7039-0\n","The Global IBM: Leadership in Multinational Management\n","374\n","ISBN\n","9780396092599\n","ISBN\n","0-87584-654-8\n","MIT Press\n","Steinhilper, Ulrich\n","ISBN\n","1-872836-75-5\n","ISBN\n","978-1-4401-9258-6\n","Watson, Thomas Jr.\n","Father, Son & Co: My Life at IBM and Beyond\n","ISBN\n","0-553-29023-1\n","edit\n","sister projects\n","Definitions\n","Media\n","News\n","Quotations\n","Texts\n","Textbooks\n","Resources\n","Official website\n","\n","IBM companies\n","OpenCorporates\n","Google\n","SEC filings\n","Yahoo!\n","v\n","t\n","e\n","IBM\n","History\n","History\n","Mergers and acquisitions\n","PC business acquisition by Lenovo\n","Products\n","Mainframe\n","IBM Z\n","Power microprocessors\n","Power Systems\n","Storage\n","FlashSystem\n","DS8000\n","Q System One\n","Blue Gene\n","Cell microprocessors\n","PowerPC\n","Midrange computer\n","Personal Computer\n","Selectric\n","ThinkPad\n","alphaWorks\n","Carbon Design System\n","Cloud\n","Cloudant\n","Cognos Analytics\n","Connections\n","Criminal Reduction Utilising Statistical History\n","Fortran\n","ILOG\n","Information Management Software\n","Lotus Software\n","Mainframe operating systems\n","Mashup Center\n","Planning Analytics\n","PureQuery\n","Quantum Platform\n","Qiskit\n","OpenQASM\n","Rational Software\n","SPSS\n","Tivoli Software\n","Service Automation Manager\n","Watson\n","Watsonx\n","WebSphere\n","Apptio\n","Center for The Business of Government\n","Consulting\n","Promontory\n","Kenexa\n","International subsidiaries\n","India\n","Press\n","Red Hat\n","Research\n","The Weather Company\n","Weather Underground\n","AdStar\n","AIM alliance\n","Kaleida Labs\n","Taligent\n","Ambra Computer\n","Cognos\n","EduQuest\n","Kyndryl\n","Lexmark\n","Merative\n","Microelectronics\n","Product Center\n","Science Research Associates\n","Service Bureau\n","1250 René-Lévesque\n","One Atlantic Center\n","Rome Software Lab\n","Toronto Software Lab\n","330 North Wabash\n","Honolulu\n","Seattle\n","Thomas J. Watson Research Center\n","Hakozaki Facility\n","Yamato Facility\n","Cambridge Scientific Center\n","IBM Hursley\n","Canada Head Office Building\n","IBM Rochester\n","Academy of Technology\n","Deep Thunder\n","Developer\n","Develothon\n","Fellow\n","The Great Mind Challenge\n","Linux Technology Center\n","SkillsBuild\n","Smarter Planet\n","Virtual Universe Community\n","World Community Grid\n","Automated teller machine\n","Cynefin framework\n","DRAM\n","Electronic keypunch\n","Floppy disk\n","Hard disk drive\n","Magnetic stripe card\n","Relational model\n","Sabre airline reservation system\n","Scanning tunneling microscope\n","Financial swaps\n","Universal Product Code\n","Big Blue\n","Commercial Processing Workload\n","Customer engineer\n","Globally integrated enterprise\n","e-business\n","Think slogan\n","CEOs\n","Thomas J. Watson\n","Thomas Watson Jr.\n","T. Vincent Learson\n","Frank T. Cary\n","John R. Opel\n","John Fellows Akers\n","Louis V. Gerstner Jr.\n","Samuel J. Palmisano\n","Ginni Rometty\n","Arvind Krishna\n","Thomas Buberl\n","Michael L. Eskew\n","David Farr\n","Alex Gorsky\n","Michelle J. Howard\n","Arvind Krishna\n","Andrew N. Liveris\n","Martha E. Pollack\n","Virginia M. Rometty\n","Joseph R. Swedish\n","Sidney Taurel\n","Peter R. Voser\n","A Boy and His Atom\n","American football\n","Rugby union\n","Common Public License\n","IBM Public License\n","Deep Blue\n","Deep Thought\n","Dynamic infrastructure\n","GlobalFoundries\n","GUIDE International\n","IBM and the Holocaust\n","International chess tournament\n","Lucifer cipher\n","Mathematica\n","IBM Plex\n","SHARE computing\n","ScicomP\n","Unions\n","Category\n","Commons\n","Navigational boxes\n","FOSS\n","Midrange computers\n","Operating systems\n","Personal computers\n","System/360\n","System/370\n","Typewriters\n","Vacuum tube computers\n","v\n","t\n","e\n","Dow Jones Industrial Average\n","3M\n","American Express\n","Amgen\n","Apple\n","Boeing\n","Caterpillar\n","Chevron\n","Cisco\n","Coca-Cola\n","Disney\n","Dow\n","Goldman Sachs\n","Home Depot\n","Honeywell\n","IBM\n","Intel\n","Johnson & Johnson\n","JPMorgan Chase\n","McDonald's\n","Merck\n","Microsoft\n","Nike\n","Procter & Gamble\n","Salesforce\n","Travelers\n","UnitedHealth\n","Verizon\n","Visa\n","Walgreens Boots Alliance\n","Walmart\n","v\n","t\n","e\n","Acer\n","Apple\n","Asus\n","Dell\n","Fujitsu\n","Huawei\n","HP\n","Lenovo\n","LG\n","Microsoft\n","MSI\n","NEC\n","Panasonic\n","Razer\n","Samsung\n","Sharp\n","Dynabook\n","Vaio\n","Cisco\n","Dell EMC\n","HPE\n","IBM\n","Inspur\n","NetApp\n","Oracle\n","Fujitsu\n","HPE\n","IBM\n","Largest IT companies\n","Computer hardware manufacturers\n","Home computer hardware companies\n","Server hardware\n","Mainframe computers\n","v\n","t\n","e\n","information storage\n","ADATA\n","Amazon\n","Apple\n","Dell\n","Dell EMC\n","Fujitsu\n","Google\n","Hitachi Data Systems\n","Hewlett Packard Enterprise\n","IBM\n","Kingston Technology\n","Kioxia\n","Microsoft\n","NetApp\n","Oracle\n","Plextor\n","Samsung\n","Seagate\n","Silicon Power\n","Sony\n","Transcend Information\n","Western Digital\n","v\n","t\n","e\n","software\n","Adobe\n","Amadeus IT Group\n","Amazon\n","Apple\n","Autodesk\n","Citrix\n","FIS\n","Google\n","HPE\n","IBM\n","Intuit\n","Infor\n","Microsoft\n","Oracle\n","Quest Software\n","Sage Group\n","SAP\n","Tencent\n","Largest IT companies\n","Largest software companies\n","Category:Software companies\n","v\n","t\n","e\n","Electronics industry in the United States\n","Home appliances\n","Apple\n","Bose\n","Cisco\n","Corsair\n","Dell\n","Dolby Laboratories\n","Element Electronics\n","Emerson Radio\n","Harman\n","Honeywell\n","HP\n","InFocus\n","Jensen Electronics\n","Kenmore\n","Kingston\n","Kimball\n","Koss\n","Lexmark\n","Logitech\n","Magnavox\n","Marantz\n","Memorex\n","Microsoft\n","Monster\n","Plantronics\n","Planar Systems\n","Razer\n","Seagate\n","Seiki Digital\n","Skullcandy\n","Turtle Beach\n","ViewSonic\n","Vizio\n","Western Digital\n","HGST\n","SanDisk\n","Westinghouse Electric Company\n","Westinghouse Electronics\n","Xerox\n","Electronic components\n","3M\n","Achronix\n","Analog Devices\n","Maxim Integrated\n","Applied Materials\n","Altera\n","AVX\n","Cirque\n","Diodes Inc.\n","Flex\n","Jabil\n","KEMET\n","Maxwell Technologies\n","Sanmina\n","Vishay\n","Semiconductor devices\n","AMD\n","Ampere Computing\n","Apple\n","Broadcom\n","Cypress Semiconductor\n","GlobalFoundries\n","IBM\n","Intel\n","Interlink\n","KLA-Tencor\n","Lam Research\n","Lattice\n","Marvell Technology\n","Microchip\n","Atmel\n","Micron\n","NetApp\n","Nimbus Data\n","Nvidia\n","Mellanox\n","NXP\n","Onsemi\n","Qualcomm\n","Silicon Image\n","Synaptics\n","Tabula\n","Texas Instruments\n","Xilinx\n","Zilog\n","Mobile devices\n","Apple\n","BLU\n","Google\n","Lenovo\n","Motorola Mobility\n","Cadence Design Systems\n","Cray\n","GE\n","RCA\n","Oracle Corporation\n","Synopsys\n","Actel\n","Atari Corporation\n","Commodore\n","Compaq\n","Fairchild\n","Freescale\n","LSI\n","Microsemi\n","National Semiconductor\n","Palm\n","Philco\n","RCA\n","Signetics\n","Silicon Graphics\n","Solectron\n","Sun Microsystems\n","Zenith Electronics\n","Authority control databases\n","\n","ISNI\n","VIAF\n","Norway\n","Spain\n","France\n","BnF data\n","Catalonia\n","Germany\n","Israel\n","United States\n","Sweden\n","Latvia\n","Japan\n","Czech Republic\n","Australia\n","Greece\n","Korea\n","Croatia\n","Poland\n","Portugal\n","CiNii\n","MusicBrainz\n","Museum of Modern Art\n","2\n","ULAN\n","Trove\n","SNAC\n","IdRef\n","https://en.wikipedia.org/w/index.php?title=IBM&oldid=1192877382\n","Categories\n","IBM\n","1888 establishments in New York (state)\n","Technology companies established in 1888\n","American companies established in 1888\n","Cloud computing providers\n","Collier Trophy recipients\n","Companies based in Westchester County, New York\n","Companies in the Dow Jones Industrial Average\n","Companies listed on the New York Stock Exchange\n","Computer companies of the United States\n","Computer hardware companies\n","Computer systems companies\n","Data companies\n","Data quality companies\n","Display technology companies\n","Electronics companies of the United States\n","Information technology consulting firms of the United States\n","Multinational companies headquartered in the United States\n","National Medal of Technology recipients\n","Outsourcing companies\n","Point of sale companies\n","Software companies based in New York (state)\n","Storage Area Network companies\n","Software companies of the United States\n","International information technology consulting firms\n","CS1: Julian–Gregorian uncertainty\n","CS1 German-language sources (de)\n","All articles with dead external links\n","Articles with dead external links from August 2023\n","Articles with permanently dead external links\n","Webarchive template wayback links\n","Articles with dead external links from July 2018\n","Articles with dead external links from March 2018\n","Articles with short description\n","Short description matches Wikidata\n","Use American English from February 2019\n","All Wikipedia articles written in American English\n","Use mdy dates from February 2023\n","Articles containing potentially dated statements from 2022\n","All articles containing potentially dated statements\n","All articles with unsourced statements\n","Articles with unsourced statements from September 2020\n","Articles containing potentially dated statements from 2016\n","Wikipedia articles containing buzzwords from October 2020\n","Pages using Sister project links with default search\n","OpenCorporates groupings\n","Articles with ISNI identifiers\n","Articles with VIAF identifiers\n","Articles with BIBSYS identifiers\n","Articles with BNE identifiers\n","Articles with BNF identifiers\n","Articles with BNFdata identifiers\n","Articles with CANTICN identifiers\n","Articles with GND identifiers\n","Articles with J9U identifiers\n","Articles with LCCN identifiers\n","Articles with Libris identifiers\n","Articles with LNB identifiers\n","Articles with NDL identifiers\n","Articles with NKC identifiers\n","Articles with NLA identifiers\n","Articles with NLG identifiers\n","Articles with NLK identifiers\n","Articles with NSK identifiers\n","Articles with PLWABN identifiers\n","Articles with PortugalA identifiers\n","Articles with CINII identifiers\n","Articles with MusicBrainz identifiers\n","Articles with MoMA identifiers\n","Articles with ULAN identifiers\n","Articles with Trove identifiers\n","Articles with SNAC-ID identifiers\n","Articles with SUDOC identifiers\n","Creative Commons Attribution-ShareAlike License 4.0\n","\n","Terms of Use\n","Privacy Policy\n","Wikimedia Foundation, Inc.\n","Privacy policy\n","About Wikipedia\n","Disclaimers\n","Contact Wikipedia\n","Code of Conduct\n","Developers\n","Statistics\n","Cookie statement\n","Mobile view\n","\n","\n"]}],"source":["# Find all <a> tags (anchor tags) in the HTML\n","links = soup.find_all('a')\n","\n","# Iterate through the list of links and print their text\n","for link in links:\n","    print(link.text)"]},{"cell_type":"markdown","metadata":{},"source":["**Custom Data Extraction**\n","\n","Web scraping allows you to navigate the HTML structure and extract specific information based on your requirements. This may involve finding specific tags, attributes, or text content within the HTML document.\n","\n","**Using BeautifulSoup for HTML Parsing**\n","\n","Beautiful Soup is a powerful tool for navigating and extracting specific parts of a web page. It allows you to find elements based on their tags, attributes, or text, making it easier to extract the information you're interested in.\n","\n","**Using pandas `read_html` for Table Extraction**\n","\n","On many websites, data is neatly organized in tables. Pandas, a Python library, provides a function called read_html, which can automatically extract data from these tables and present it in a format suitable for analysis. It's similar to taking a table from a webpage and importing it into a spreadsheet for further analysis."]},{"cell_type":"markdown","id":"cd501e03-9401-4e9b-955e-ab77abadb5b3","metadata":{},"source":["## Beautiful Soup Object\n"]},{"cell_type":"markdown","id":"206ee994-c30d-489b-b23f-6594696d69c4","metadata":{},"source":["Beautiful Soup is a Python library for pulling data out of HTML and XML files, we will focus on HTML files. This is accomplished by representing the HTML as a set of objects with methods used to parse the HTML.  We can navigate the HTML as a tree, and/or filter out what we are looking for.\n","\n","Consider the following HTML:\n"]},{"cell_type":"code","execution_count":63,"id":"7e810b0d-614d-433e-891e-957a69b69c78","metadata":{},"outputs":[{"data":{"text/html":["<!DOCTYPE html>\n","<html>\n","<head>\n","<title>Page Title</title>\n","</head>\n","<body>\n","<h3><b id='boldest'>Lebron James</b></h3>\n","<p> Salary: $ 92,000,000 </p>\n","<h3> Stephen Curry</h3>\n","<p> Salary: $85,000, 000 </p>\n","<h3> Kevin Durant </h3>\n","<p> Salary: $73,200, 000</p>\n","</body>\n","</html>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<!DOCTYPE html>\n","<html>\n","<head>\n","<title>Page Title</title>\n","</head>\n","<body>\n","<h3><b id='boldest'>Lebron James</b></h3>\n","<p> Salary: $ 92,000,000 </p>\n","<h3> Stephen Curry</h3>\n","<p> Salary: $85,000, 000 </p>\n","<h3> Kevin Durant </h3>\n","<p> Salary: $73,200, 000</p>\n","</body>\n","</html>"]},{"cell_type":"markdown","id":"1da3a0d5-0905-42db-842b-c69763deb13c","metadata":{},"source":["We can store it as a string in the variable HTML:\n"]},{"cell_type":"code","execution_count":64,"id":"e92f7643-15ea-4f8a-8e02-bb54a81041ad","metadata":{},"outputs":[],"source":["html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\""]},{"cell_type":"markdown","id":"de177f38-15f1-431c-8d11-36113ad6690f","metadata":{},"source":["To parse a document, pass it into the <code>BeautifulSoup</code> constructor. The <code>BeautifulSoup</code> object represents the document as a nested data structure:\n"]},{"cell_type":"code","execution_count":65,"id":"aa18d377-2b5c-4452-bf84-b61e653f6e8b","metadata":{},"outputs":[],"source":["soup = BeautifulSoup(html, 'html5lib')"]},{"cell_type":"markdown","id":"8dc8d60e-1f03-4260-906c-2dd0484e357d","metadata":{},"source":["First, the document is converted to Unicode (similar to ASCII) and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The <code>BeautifulSoup</code> object can create other types of objects. In this lab, we will cover <code>BeautifulSoup</code> and <code>Tag</code> objects, that for the purposes of this lab are identical. Finally, we will look at <code>NavigableString</code> objects.\n"]},{"cell_type":"markdown","id":"c16679d4-fa8c-42a3-a490-39c5477f6886","metadata":{},"source":["We can use the method <code>prettify()</code> to display the HTML in the nested structure:\n"]},{"cell_type":"code","execution_count":66,"id":"a08cff02-80d3-4107-9454-b21770756ec4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<!DOCTYPE html>\n","<html>\n"," <head>\n","  <title>\n","   Page Title\n","  </title>\n"," </head>\n"," <body>\n","  <h3>\n","   <b id=\"boldest\">\n","    Lebron James\n","   </b>\n","  </h3>\n","  <p>\n","   Salary: $ 92,000,000\n","  </p>\n","  <h3>\n","   Stephen Curry\n","  </h3>\n","  <p>\n","   Salary: $85,000, 000\n","  </p>\n","  <h3>\n","   Kevin Durant\n","  </h3>\n","  <p>\n","   Salary: $73,200, 000\n","  </p>\n"," </body>\n","</html>\n","\n"]}],"source":["print(soup.prettify())"]},{"cell_type":"markdown","id":"78259c87-f479-4aed-a35e-6e442a1c7377","metadata":{},"source":["## Tags\n"]},{"cell_type":"markdown","id":"c65fef1c-2345-4b78-a7b8-33bcc5feb312","metadata":{},"source":["Let's say we want the  title of the page and the name of the top paid player. We can use the <code>Tag</code>. The <code>Tag</code> object corresponds to an HTML tag in the original document, for example, the tag title.\n"]},{"cell_type":"code","execution_count":67,"id":"22043cc8-2059-4512-bb30-e83f0a2ad3d0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tag object: <title>Page Title</title>\n"]}],"source":["tag_object=soup.title\n","print(\"tag object:\",tag_object)"]},{"cell_type":"markdown","id":"bef2e51e-a5a3-452b-8c1e-bb500ffe1d65","metadata":{},"source":["we can see the tag type <code>bs4.element.Tag</code>\n"]},{"cell_type":"code","execution_count":68,"id":"30cedc94-e258-4da8-82e1-08de13e5104b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tag object type: <class 'bs4.element.Tag'>\n"]}],"source":["print(\"tag object type:\",type(tag_object))"]},{"cell_type":"markdown","id":"f125ff93-4d10-47a1-b853-cfcf593f8ff6","metadata":{},"source":["If there is more than one <code>Tag</code> with the same name, the first element with that <code>Tag</code> name is called. This corresponds to the most paid player:\n"]},{"cell_type":"code","execution_count":69,"id":"bbbf01e9-7518-49ca-bfcd-9247f76be188","metadata":{},"outputs":[{"data":{"text/plain":["<h3><b id=\"boldest\">Lebron James</b></h3>"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["tag_object=soup.h3\n","tag_object"]},{"cell_type":"markdown","id":"c6834365-e3aa-4d59-967a-919b3eab39b8","metadata":{},"source":["Enclosed in the bold attribute <code>b</code>, it helps to use the tree representation. We can navigate down the tree using the child attribute to get the name.\n"]},{"cell_type":"markdown","id":"a2f99c47-22f2-4d23-b44a-084797d0de61","metadata":{},"source":["### Children, Parents, and Siblings\n"]},{"cell_type":"markdown","id":"95aa8115-e51c-4a70-8912-de6e45adc50c","metadata":{},"source":["As stated above, the <code>Tag</code> object is a tree of objects. We can access the child of the tag or navigate down the branch as follows:\n"]},{"cell_type":"code","execution_count":70,"id":"437cc21f-34b8-438a-b1a2-d321ddc90ddc","metadata":{},"outputs":[{"data":{"text/plain":["<b id=\"boldest\">Lebron James</b>"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["tag_child =tag_object.b\n","tag_child"]},{"cell_type":"markdown","id":"cb3039ad-7e29-4200-9c7f-a4bb0d491f3a","metadata":{},"source":["You can access the parent with the <code> parent</code>.\n"]},{"cell_type":"code","execution_count":71,"id":"3577e9f0-1d58-4735-902e-4f4ec13732d0","metadata":{},"outputs":[{"data":{"text/plain":["<h3><b id=\"boldest\">Lebron James</b></h3>"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["parent_tag=tag_child.parent\n","parent_tag"]},{"cell_type":"markdown","id":"ad242a4a-06a5-4a8d-961c-099e8a2b8ae6","metadata":{},"source":["this is identical to:\n"]},{"cell_type":"code","execution_count":72,"id":"ee267842-01ec-448d-9f38-4e1426001575","metadata":{},"outputs":[{"data":{"text/plain":["<h3><b id=\"boldest\">Lebron James</b></h3>"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["tag_object"]},{"cell_type":"markdown","id":"0a5828cd-f962-48ed-8e61-a49f05f358f3","metadata":{},"source":["<code>tag_object</code> parent is the <code>body</code> element.\n"]},{"cell_type":"code","execution_count":73,"id":"00755a73-02ae-483f-90ad-88d4bb82d779","metadata":{},"outputs":[{"data":{"text/plain":["<body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["tag_object.parent"]},{"cell_type":"markdown","id":"783efde9-e42b-4262-b996-1dbb128a0533","metadata":{},"source":["<code>tag_object</code> sibling is the <code>paragraph</code> element.\n"]},{"cell_type":"code","execution_count":74,"id":"fc246920-2197-41cc-ae6e-80ee1d19f336","metadata":{},"outputs":[{"data":{"text/plain":["<p> Salary: $ 92,000,000 </p>"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["sibling_1=tag_object.next_sibling\n","sibling_1"]},{"cell_type":"markdown","id":"ad43649b-6c29-4eae-a9fd-c103bc1dba2a","metadata":{},"source":["`sibling_2` is the `header` element, which is also a sibling of both `sibling_1` and `tag_object`\n"]},{"cell_type":"code","execution_count":75,"id":"68b4f9fa-3322-4296-9b77-67656346f72c","metadata":{},"outputs":[{"data":{"text/plain":["<h3> Stephen Curry</h3>"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["sibling_2=sibling_1.next_sibling\n","sibling_2"]},{"cell_type":"markdown","id":"2385f2cc-869e-4ee6-8de7-5aef7bd09198","metadata":{},"source":["<h3 id=\"first_question\">Exercise: <code>next_sibling</code></h3>\n"]},{"cell_type":"markdown","id":"c139e030-51cd-4583-bb12-f3bc515b554a","metadata":{},"source":["Use the object <code>sibling\\_2</code> and the method <code>next_sibling</code> to find the salary of Stephen Curry:\n"]},{"cell_type":"code","execution_count":null,"id":"59854658-f103-474b-93af-f1ad42ce3a61","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"6a573f0e-4c94-4687-b4ad-f935b172eac9","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","sibling_2.next_sibling\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"c42a04c3-3d8a-48d1-b182-66450f8701ff","metadata":{},"source":["### HTML Attributes\n"]},{"cell_type":"markdown","id":"95545613-a8cf-4799-8384-3bd232ab59cd","metadata":{},"source":["If the tag has attributes, the tag <code>id=\"boldest\"</code> has an attribute <code>id</code> whose value is <code>boldest</code>. You can access a tag's attributes by treating the tag like a dictionary:\n"]},{"cell_type":"code","execution_count":76,"id":"2bb697aa-ba5b-4220-ac9c-d2ea22aa8a01","metadata":{},"outputs":[{"data":{"text/plain":["'boldest'"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["tag_child['id']"]},{"cell_type":"markdown","id":"2afb4d01-5040-4464-913a-b220b666a3c7","metadata":{},"source":["You can access that dictionary directly as <code>attrs</code>:\n"]},{"cell_type":"code","execution_count":77,"id":"baf7f1b1-ecc3-45bf-98cb-cacc2166d542","metadata":{},"outputs":[{"data":{"text/plain":["{'id': 'boldest'}"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["tag_child.attrs"]},{"cell_type":"markdown","id":"081b9bb6-e6ab-43b0-84c0-9e2542581b08","metadata":{},"source":["You can also work with Multi-valued attributes. Check out <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01\">\\[1]</a> for more.\n"]},{"cell_type":"markdown","id":"5bcb61d1-c63f-4f47-b975-f920ccd12e65","metadata":{},"source":["We can also obtain the content of the attribute of the <code>tag</code> using the Python <code>get()</code> method.\n"]},{"cell_type":"code","execution_count":78,"id":"993017b9-e3a3-4eae-8d0c-02ce3f5787d4","metadata":{},"outputs":[{"data":{"text/plain":["'boldest'"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["tag_child.get('id')"]},{"cell_type":"markdown","id":"7166293e-6803-48a8-8163-a5892443b1ae","metadata":{},"source":["### Navigable String\n"]},{"cell_type":"markdown","id":"7e630937-96f5-4359-b668-8174232993ad","metadata":{},"source":["A string corresponds to a bit of text or content within a tag. Beautiful Soup uses the <code>NavigableString</code> class to contain this text. In our HTML we can obtain the name of the first player by extracting the string of the <code>Tag</code> object <code>tag_child</code> as follows:\n"]},{"cell_type":"code","execution_count":79,"id":"74a820e3-8f27-4e0f-891c-da37e63884c3","metadata":{},"outputs":[{"data":{"text/plain":["'Lebron James'"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["tag_string=tag_child.string\n","tag_string"]},{"cell_type":"markdown","id":"d573ea8c-6937-42ca-ac7f-c70505d200a7","metadata":{},"source":["we can verify the type is Navigable String\n"]},{"cell_type":"code","execution_count":80,"id":"ca55c077-6c1c-45b8-8c9a-f81aaa95d3b1","metadata":{},"outputs":[{"data":{"text/plain":["bs4.element.NavigableString"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["type(tag_string)"]},{"cell_type":"markdown","id":"03020fee-6a50-4f78-a460-934414330961","metadata":{},"source":["A NavigableString is similar to a Python string or Unicode string. To be more precise, the main difference is that it also supports some <code>BeautifulSoup</code> features. We can convert it to string object in Python:\n"]},{"cell_type":"code","execution_count":81,"id":"cb523ce9-2522-48a5-890c-5d92f1f78240","metadata":{},"outputs":[{"data":{"text/plain":["'Lebron James'"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["unicode_string = str(tag_string)\n","unicode_string"]},{"cell_type":"markdown","id":"122f5c28-d2ba-49b0-94ea-d90610c44177","metadata":{},"source":["## Filter\n"]},{"cell_type":"markdown","id":"d42cf065-d0ad-4124-8b94-a8fae600b0d4","metadata":{},"source":["Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string. Consider the following HTML of rocket launches:\n"]},{"cell_type":"code","execution_count":82,"id":"04bee9fb-1446-481b-9661-7440554d4074","metadata":{},"outputs":[{"data":{"text/html":["<table>\n","  <tr>\n","    <td id='flight' >Flight No</td>\n","    <td>Launch site</td> \n","    <td>Payload mass</td>\n","   </tr>\n","  <tr> \n","    <td>1</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n","    <td>300 kg</td>\n","  </tr>\n","  <tr>\n","    <td>2</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n","    <td>94 kg</td>\n","  </tr>\n","  <tr>\n","    <td>3</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n","    <td>80 kg</td>\n","  </tr>\n","</table>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<table>\n","  <tr>\n","    <td id='flight' >Flight No</td>\n","    <td>Launch site</td> \n","    <td>Payload mass</td>\n","   </tr>\n","  <tr> \n","    <td>1</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n","    <td>300 kg</td>\n","  </tr>\n","  <tr>\n","    <td>2</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n","    <td>94 kg</td>\n","  </tr>\n","  <tr>\n","    <td>3</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n","    <td>80 kg</td>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","id":"3c3a7012-5433-4ce1-a7d0-f52abbb50482","metadata":{},"source":["We can store it as a string in the variable <code>table</code>:\n"]},{"cell_type":"code","execution_count":83,"id":"b7dac682-3e5c-458a-b0fe-fd8abe6b64b5","metadata":{},"outputs":[],"source":["table=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\""]},{"cell_type":"code","execution_count":84,"id":"cf406046-5be5-4025-bf87-436eb366e21b","metadata":{},"outputs":[],"source":["table_bs = BeautifulSoup(table, 'html5lib')"]},{"cell_type":"markdown","id":"e7176649-ae82-444c-a4b7-f87d6731fb3c","metadata":{},"source":["## find_All\n"]},{"cell_type":"markdown","id":"763f0eb5-4abd-48b1-8f7d-0362da7cfa27","metadata":{},"source":["The <code>find_all()</code> method looks through a tag's descendants and retrieves all descendants that match your filters.\n","\n","<p>\n","The Method signature for <code>find_all(name, attrs, recursive, string, limit, **kwargs)<c/ode>\n","</p>\n"]},{"cell_type":"markdown","id":"2b1b490e-58d0-4e7e-a345-83525ba130c7","metadata":{},"source":["### Name\n"]},{"cell_type":"markdown","id":"4704ef45-47f5-48ef-a2dc-a3c711e65423","metadata":{},"source":["When we set the <code>name</code> parameter to a tag name, the method will extract all the tags with that name and its children.\n"]},{"cell_type":"code","execution_count":85,"id":"e2793cd7-9833-46a0-a3d0-7fcb3324b489","metadata":{},"outputs":[{"data":{"text/plain":["[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n"," <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n"," <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n"," <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>]"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["table_rows=table_bs.find_all('tr')\n","table_rows"]},{"cell_type":"markdown","id":"3040b3c5-f69f-4a17-8f57-78248d38fd47","metadata":{},"source":["The result is a Python iterable just like a list, each element is a <code>tag</code> object:\n"]},{"cell_type":"code","execution_count":86,"id":"80ef402c-323b-4334-8052-90cfc7c3e2df","metadata":{},"outputs":[{"data":{"text/plain":["<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["first_row =table_rows[0]\n","first_row"]},{"cell_type":"markdown","id":"85f7d547-ca41-4690-bac1-3fc12caed447","metadata":{},"source":["The type is <code>tag</code>\n"]},{"cell_type":"code","execution_count":87,"id":"1092f8e2-be14-49da-8e91-9d4950a0adeb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'bs4.element.Tag'>\n"]}],"source":["print(type(first_row))"]},{"cell_type":"markdown","id":"d9dc1fd9-8ca1-405a-8ace-b1d78129cc0c","metadata":{},"source":["we can obtain the child\n"]},{"cell_type":"code","execution_count":88,"id":"cdb0caab-eb13-4bf3-82fa-83518e8671f1","metadata":{},"outputs":[{"data":{"text/plain":["<td id=\"flight\">Flight No</td>"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["first_row.td"]},{"cell_type":"markdown","id":"2d229567-721d-4fff-8bfc-1fdd69211f38","metadata":{},"source":["If we iterate through the list, each element corresponds to a row in the table:\n"]},{"cell_type":"code","execution_count":89,"id":"f00cc0d6-e600-4e01-b1c5-795ee1b67804","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["row 0 is <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>\n","row 1 is <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>\n","row 2 is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\n","row 3 is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>\n"]}],"source":["for i,row in enumerate(table_rows):\n","    print(\"row\",i,\"is\",row)\n","    "]},{"cell_type":"markdown","id":"5ebf6cb5-652f-47ed-ac9e-6a52f0270bbc","metadata":{},"source":["As <code>row</code> is a <code>cell</code> object, we can apply the method <code>find_all</code> to it and extract table cells in the object <code>cells</code> using the tag <code>td</code>, this is all the children with the name <code>td</code>. The result is a list, each element corresponds to a cell and is a <code>Tag</code> object, we can iterate through this list as well. We can extract the content using the <code>string</code> attribute.\n"]},{"cell_type":"code","execution_count":90,"id":"32878dff-acd7-4e85-a3ee-0450f691df0f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["row 0\n","colunm 0 cell <td id=\"flight\">Flight No</td>\n","colunm 1 cell <td>Launch site</td>\n","colunm 2 cell <td>Payload mass</td>\n","row 1\n","colunm 0 cell <td>1</td>\n","colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>\n","colunm 2 cell <td>300 kg</td>\n","row 2\n","colunm 0 cell <td>2</td>\n","colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n","colunm 2 cell <td>94 kg</td>\n","row 3\n","colunm 0 cell <td>3</td>\n","colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>\n","colunm 2 cell <td>80 kg</td>\n"]}],"source":["for i,row in enumerate(table_rows):\n","    print(\"row\",i)\n","    cells=row.find_all('td')\n","    for j,cell in enumerate(cells):\n","        print('colunm',j,\"cell\",cell)"]},{"cell_type":"markdown","id":"22e56f75-3cdf-4df7-a617-b65df9c9a380","metadata":{},"source":["If we use a list we can match against any item in that list.\n"]},{"cell_type":"code","execution_count":91,"id":"d77c24bd-d9dd-4c48-ada7-995c7888765c","metadata":{},"outputs":[{"data":{"text/plain":["[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n"," <td id=\"flight\">Flight No</td>,\n"," <td>Launch site</td>,\n"," <td>Payload mass</td>,\n"," <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n"," <td>1</td>,\n"," <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>,\n"," <td>300 kg</td>,\n"," <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n"," <td>2</td>,\n"," <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n"," <td>94 kg</td>,\n"," <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>,\n"," <td>3</td>,\n"," <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>,\n"," <td>80 kg</td>]"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n","list_input"]},{"cell_type":"markdown","id":"3d19ed0d-e1e5-495b-97d4-39873d91577f","metadata":{},"source":["### Attributes\n"]},{"cell_type":"markdown","id":"f1a2b1d2-daac-48a3-b27f-710ac1db020d","metadata":{},"source":["If the argument is not recognized it will be turned into a filter on the tag's attributes. For example with the <code>id</code> argument, Beautiful Soup will filter against each tag's <code>id</code> attribute. For example, the first <code>td</code> elements have a value of <code>id</code> of <code>flight</code>, therefore we can filter based on that <code>id</code> value.\n"]},{"cell_type":"code","execution_count":92,"id":"432269b4-4247-4a57-be16-d5ffb5a1df84","metadata":{},"outputs":[{"data":{"text/plain":["[<td id=\"flight\">Flight No</td>]"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["table_bs.find_all(id=\"flight\")"]},{"cell_type":"markdown","id":"f085cd43-7b3b-40f0-b3db-21a852c6fe75","metadata":{},"source":["We can find all the elements that have links to the Florida Wikipedia page:\n"]},{"cell_type":"code","execution_count":93,"id":"570b298c-b955-4ffa-9f62-f4325b59a69b","metadata":{},"outputs":[{"data":{"text/plain":["[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n"," <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n","list_input"]},{"cell_type":"markdown","id":"c0a1cdd5-8e06-420f-9ecb-a966e164d2ad","metadata":{},"source":["If we set the <code>href</code> attribute to True, regardless of what the value is, the code finds all tags with <code>href</code> value:\n"]},{"cell_type":"code","execution_count":94,"id":"7947bc41-1d2d-46a3-bf74-d15289a167b6","metadata":{},"outputs":[{"data":{"text/plain":["[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n"," <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n"," <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["table_bs.find_all(href=True)"]},{"cell_type":"markdown","id":"86fa22e9-f94b-400d-b37c-d04b9f9985ed","metadata":{},"source":["There are other methods for dealing with attributes and other related methods. Check out the following <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01#css-selectors'>link</a>\n"]},{"cell_type":"markdown","id":"0e2a5300-23ec-42e1-b09e-525cd48415c9","metadata":{},"source":["<h3 id=\"exer_type\">Exercise: <code>find_all</code></h3>\n"]},{"cell_type":"markdown","id":"b7889a6d-4809-470b-b3c5-9666988efe5e","metadata":{},"source":["Using the logic above, find all the elements without <code>href</code> value\n"]},{"cell_type":"code","execution_count":null,"id":"1b9d3f37-6aac-4126-bca5-cff78e5675f4","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"c07eb27e-1548-42d1-9d1a-ed7483d08b03","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","table_bs.find_all(href=False)\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"869dd3e9-7d29-433f-a0f8-005ee08544d0","metadata":{},"source":["Using the soup object <code>soup</code>, find the element with the <code>id</code> attribute content set to <code>\"boldest\"</code>.\n"]},{"cell_type":"code","execution_count":null,"id":"9c4ee6f5-5666-43fd-a1c7-3176e3844756","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"1fffcc74-0e8d-40c1-9292-9f9cbedf0838","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","soup.find_all(id=\"boldest\")\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"0c3aa704-ca52-4b44-9bb9-ccaac281ef13","metadata":{},"source":["### string\n"]},{"cell_type":"markdown","id":"e1c9539d-9c2b-431e-ad5f-3de52e0dfb51","metadata":{},"source":["With string you can search for strings instead of tags, where we find all the elments with Florida:\n"]},{"cell_type":"code","execution_count":95,"id":"15b8dc84-e072-42ba-acdf-48784551f80e","metadata":{},"outputs":[{"data":{"text/plain":["['Florida', 'Florida']"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["table_bs.find_all(string=\"Florida\")"]},{"cell_type":"markdown","id":"eb92da7f-8a50-4a09-8ccf-b5009aa834c0","metadata":{},"source":["## find\n"]},{"cell_type":"markdown","id":"711c8beb-cdef-4326-8305-b35f4f8ad5c0","metadata":{},"source":["The <code>find_all()</code> method scans the entire document looking for results. It’s useful if you are looking for one element, as you can use the <code>find()</code> method to find the first element in the document. Consider the following two tables:\n"]},{"cell_type":"code","execution_count":96,"id":"ec8f4a51-d74b-404a-8ce2-3e92d8a678dd","metadata":{},"outputs":[{"data":{"text/html":["<h3>Rocket Launch </h3>\n","\n","<p>\n","<table class='rocket'>\n","  <tr>\n","    <td>Flight No</td>\n","    <td>Launch site</td> \n","    <td>Payload mass</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Florida</td>\n","    <td>300 kg</td>\n","  </tr>\n","  <tr>\n","    <td>2</td>\n","    <td>Texas</td>\n","    <td>94 kg</td>\n","  </tr>\n","  <tr>\n","    <td>3</td>\n","    <td>Florida </td>\n","    <td>80 kg</td>\n","  </tr>\n","</table>\n","</p>\n","<p>\n","\n","<h3>Pizza Party  </h3>\n","  \n","    \n","<table class='pizza'>\n","  <tr>\n","    <td>Pizza Place</td>\n","    <td>Orders</td> \n","    <td>Slices </td>\n","   </tr>\n","  <tr>\n","    <td>Domino's Pizza</td>\n","    <td>10</td>\n","    <td>100</td>\n","  </tr>\n","  <tr>\n","    <td>Little Caesars</td>\n","    <td>12</td>\n","    <td >144 </td>\n","  </tr>\n","  <tr>\n","    <td>Papa John's </td>\n","    <td>15 </td>\n","    <td>165</td>\n","  </tr>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%html\n","<h3>Rocket Launch </h3>\n","\n","<p>\n","<table class='rocket'>\n","  <tr>\n","    <td>Flight No</td>\n","    <td>Launch site</td> \n","    <td>Payload mass</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Florida</td>\n","    <td>300 kg</td>\n","  </tr>\n","  <tr>\n","    <td>2</td>\n","    <td>Texas</td>\n","    <td>94 kg</td>\n","  </tr>\n","  <tr>\n","    <td>3</td>\n","    <td>Florida </td>\n","    <td>80 kg</td>\n","  </tr>\n","</table>\n","</p>\n","<p>\n","\n","<h3>Pizza Party  </h3>\n","  \n","    \n","<table class='pizza'>\n","  <tr>\n","    <td>Pizza Place</td>\n","    <td>Orders</td> \n","    <td>Slices </td>\n","   </tr>\n","  <tr>\n","    <td>Domino's Pizza</td>\n","    <td>10</td>\n","    <td>100</td>\n","  </tr>\n","  <tr>\n","    <td>Little Caesars</td>\n","    <td>12</td>\n","    <td >144 </td>\n","  </tr>\n","  <tr>\n","    <td>Papa John's </td>\n","    <td>15 </td>\n","    <td>165</td>\n","  </tr>\n"]},{"cell_type":"markdown","id":"26358b0e-3241-4ea9-a5f0-1f2b94ba3f33","metadata":{},"source":["We store the HTML as a Python string and assign <code>two_tables</code>:\n"]},{"cell_type":"code","execution_count":97,"id":"a4dde735-8119-4414-8826-e9102a4ce7bf","metadata":{},"outputs":[],"source":["two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\""]},{"cell_type":"markdown","id":"c48c1237-3d32-47c5-aac6-b871c4248ea1","metadata":{},"source":["We create a <code>BeautifulSoup</code> object  <code>two_tables_bs</code>\n"]},{"cell_type":"code","execution_count":98,"id":"dce81816-e1ba-43f6-be38-bb2da850519c","metadata":{},"outputs":[],"source":["two_tables_bs= BeautifulSoup(two_tables, 'html.parser')"]},{"cell_type":"markdown","id":"bcfab311-1452-4047-ac00-727c5822f014","metadata":{},"source":["We can find the first table using the tag name table\n"]},{"cell_type":"code","execution_count":99,"id":"5163611b-1c85-4dd2-9755-60a425f49aba","metadata":{},"outputs":[{"data":{"text/plain":["<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["two_tables_bs.find(\"table\")"]},{"cell_type":"markdown","id":"9d3f2f1b-1c95-448b-8d6d-9983dd674999","metadata":{},"source":["We can filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore to differentiate them.\n"]},{"cell_type":"code","execution_count":100,"id":"bd13ff13-15e4-43e2-ab9d-5568712c1dc4","metadata":{},"outputs":[{"data":{"text/plain":["<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["two_tables_bs.find(\"table\",class_='pizza')"]},{"cell_type":"markdown","id":"12927e50-5660-4013-a33b-3778f1003cd8","metadata":{},"source":["<h2 id=\"DSCW\">Downloading And Scraping The Contents Of A Web Page</h2> \n"]},{"cell_type":"markdown","id":"cac77901-1b9a-48f2-a31e-f179554fbc3d","metadata":{},"source":["We Download the contents of the web page:\n"]},{"cell_type":"code","execution_count":101,"id":"adcc5a78-5630-4c8d-99c4-37f33f22cb9e","metadata":{},"outputs":[],"source":["url = \"http://www.ibm.com\""]},{"cell_type":"markdown","id":"463f59ff-96b0-4e20-9922-9938241fefc3","metadata":{},"source":["We use <code>get</code> to download the contents of the webpage in text format and store in a variable called <code>data</code>:\n"]},{"cell_type":"code","execution_count":102,"id":"e6eede6c-20b7-46aa-8b86-1f5aa21f3871","metadata":{},"outputs":[],"source":["data  = requests.get(url).text "]},{"cell_type":"markdown","id":"36e5214f-9b54-458d-96da-116e50a3808f","metadata":{},"source":["We create a <code>BeautifulSoup</code> object using the <code>BeautifulSoup</code> constructor\n"]},{"cell_type":"code","execution_count":103,"id":"1e492a03-f519-4458-8f45-3581d99b93be","metadata":{},"outputs":[],"source":["soup = BeautifulSoup(data,\"html5lib\")  # create a soup object using the variable 'data'"]},{"cell_type":"markdown","id":"37ab294a-a581-427f-a483-140669c9365c","metadata":{},"source":["Scrape all links\n"]},{"cell_type":"code","execution_count":104,"id":"10508361-be47-4853-8501-5364b92a22de","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["https://www.ibm.com/cloud?lnk=intro\n"]}],"source":["for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n","\n","    print(link.get('href'))\n"]},{"cell_type":"markdown","id":"0fb6a580-9550-46de-8538-f29cdd8d454b","metadata":{},"source":["### Scrape all images Tags\n"]},{"cell_type":"code","execution_count":105,"id":"26b41955-58d5-4440-abe7-390ce40eac8a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<img alt=\"Portraits of IBM consultants\" class=\"bx--image__img\" id=\"image-1330004318\" loading=\"lazy\" src=\"/content/dam/adobe-cms/default-images/home-consultants.component.crop-16by9-xl.ts=1695214867398.jpg/content/adobe-cms/in/en/homepage/_jcr_content/root/table_of_contents/simple_image\"/>\n","/content/dam/adobe-cms/default-images/home-consultants.component.crop-16by9-xl.ts=1695214867398.jpg/content/adobe-cms/in/en/homepage/_jcr_content/root/table_of_contents/simple_image\n"]}],"source":["for link in soup.find_all('img'):# in html image is represented by the tag <img>\n","    print(link)\n","    print(link.get('src'))"]},{"cell_type":"markdown","id":"680fe490-51d8-41e2-9528-c603df60f2e0","metadata":{},"source":["### Scrape data from HTML tables\n"]},{"cell_type":"code","execution_count":106,"id":"f97fde7a-b2e7-4eb1-9652-c13c7e225362","metadata":{},"outputs":[],"source":["#The below url contains an html table with data about colors and color codes.\n","url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""]},{"cell_type":"markdown","id":"b3a5a6ae-3c50-4b9b-b548-33bc7ea38c51","metadata":{},"source":["Before proceeding to scrape a web site, you need to examine the contents and the way data is organized on the website. Open the above url in your browser and check how many rows and columns there are in the color table.\n"]},{"cell_type":"code","execution_count":107,"id":"8ce68de6-afda-4b0d-ba77-edf6e39f32c1","metadata":{},"outputs":[],"source":["# get the contents of the webpage in text format and store in a variable called data\n","data  = requests.get(url).text"]},{"cell_type":"code","execution_count":108,"id":"e5870454-bab4-4a8c-ba42-7dcb6cff75c4","metadata":{},"outputs":[],"source":["soup = BeautifulSoup(data,\"html5lib\")"]},{"cell_type":"code","execution_count":109,"id":"44d1446d-da29-4308-b017-0a52f0598a93","metadata":{},"outputs":[],"source":["#find a html table in the web page\n","table = soup.find('table') # in html table is represented by the tag <table>"]},{"cell_type":"code","execution_count":110,"id":"480083b6-a5f4-4d1b-b02b-6f77ea4760c7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Color Name--->Hex Code#RRGGBB\n","lightsalmon--->#FFA07A\n","salmon--->#FA8072\n","darksalmon--->#E9967A\n","lightcoral--->#F08080\n","coral--->#FF7F50\n","tomato--->#FF6347\n","orangered--->#FF4500\n","gold--->#FFD700\n","orange--->#FFA500\n","darkorange--->#FF8C00\n","lightyellow--->#FFFFE0\n","lemonchiffon--->#FFFACD\n","papayawhip--->#FFEFD5\n","moccasin--->#FFE4B5\n","peachpuff--->#FFDAB9\n","palegoldenrod--->#EEE8AA\n","khaki--->#F0E68C\n","darkkhaki--->#BDB76B\n","yellow--->#FFFF00\n","lawngreen--->#7CFC00\n","chartreuse--->#7FFF00\n","limegreen--->#32CD32\n","lime--->#00FF00\n","forestgreen--->#228B22\n","green--->#008000\n","powderblue--->#B0E0E6\n","lightblue--->#ADD8E6\n","lightskyblue--->#87CEFA\n","skyblue--->#87CEEB\n","deepskyblue--->#00BFFF\n","lightsteelblue--->#B0C4DE\n","dodgerblue--->#1E90FF\n"]}],"source":["#Get all rows from the table\n","for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n","    # Get all columns in each row.\n","    cols = row.find_all('td') # in html a column is represented by the tag <td>\n","    color_name = cols[2].string # store the value in column 3 as color_name\n","    color_code = cols[3].text # store the value in column 4 as color_code\n","    print(\"{}--->{}\".format(color_name,color_code))"]},{"cell_type":"markdown","id":"318af9c7-6f36-453e-b912-3e59eab797d7","metadata":{},"source":["## Scraping tables from a Web page using Pandas\n"]},{"cell_type":"markdown","id":"ef0e6c22-5264-4c9c-9fd1-5053c52a80c3","metadata":{},"source":["Particularly for extracting tabular data from a web page, you may also use the `read_html()` method of the Pandas library. \n"]},{"cell_type":"code","execution_count":111,"id":"27812e7d-97ba-4ac2-816d-85073798c90a","metadata":{},"outputs":[],"source":["#The below url contains an html table with data about colors and color codes.\n","url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""]},{"cell_type":"markdown","id":"67db0df5-de6f-4ccd-8aae-7d440753632b","metadata":{},"source":["You may extract all the tables from the given webpage simply by using the following commands.\n"]},{"cell_type":"code","execution_count":112,"id":"4478581c-8245-4e76-9607-72b20b38cbf3","metadata":{},"outputs":[{"data":{"text/plain":["[         0      1               2                 3                     4\n"," 0   Number  Color      Color Name  Hex Code #RRGGBB  Decimal Code (R,G,B)\n"," 1        1    NaN     lightsalmon           #FFA07A      rgb(255,160,122)\n"," 2        2    NaN          salmon           #FA8072      rgb(250,128,114)\n"," 3        3    NaN      darksalmon           #E9967A      rgb(233,150,122)\n"," 4        4    NaN      lightcoral           #F08080      rgb(240,128,128)\n"," 5        5    NaN           coral           #FF7F50       rgb(255,127,80)\n"," 6        6    NaN          tomato           #FF6347        rgb(255,99,71)\n"," 7        7    NaN       orangered           #FF4500         rgb(255,69,0)\n"," 8        8    NaN            gold           #FFD700        rgb(255,215,0)\n"," 9        9    NaN          orange           #FFA500        rgb(255,165,0)\n"," 10      10    NaN      darkorange           #FF8C00        rgb(255,140,0)\n"," 11      11    NaN     lightyellow           #FFFFE0      rgb(255,255,224)\n"," 12      12    NaN    lemonchiffon           #FFFACD      rgb(255,250,205)\n"," 13      13    NaN      papayawhip           #FFEFD5      rgb(255,239,213)\n"," 14      14    NaN        moccasin           #FFE4B5      rgb(255,228,181)\n"," 15      15    NaN       peachpuff           #FFDAB9      rgb(255,218,185)\n"," 16      16    NaN   palegoldenrod           #EEE8AA      rgb(238,232,170)\n"," 17      17    NaN           khaki           #F0E68C      rgb(240,230,140)\n"," 18      18    NaN       darkkhaki           #BDB76B      rgb(189,183,107)\n"," 19      19    NaN          yellow           #FFFF00        rgb(255,255,0)\n"," 20      20    NaN       lawngreen           #7CFC00        rgb(124,252,0)\n"," 21      21    NaN      chartreuse           #7FFF00        rgb(127,255,0)\n"," 22      22    NaN       limegreen           #32CD32        rgb(50,205,50)\n"," 23      23    NaN            lime           #00FF00          rgb(0.255.0)\n"," 24      24    NaN     forestgreen           #228B22        rgb(34,139,34)\n"," 25      25    NaN           green           #008000          rgb(0,128,0)\n"," 26      26    NaN      powderblue           #B0E0E6      rgb(176,224,230)\n"," 27      27    NaN       lightblue           #ADD8E6      rgb(173,216,230)\n"," 28      28    NaN    lightskyblue           #87CEFA      rgb(135,206,250)\n"," 29      29    NaN         skyblue           #87CEEB      rgb(135,206,235)\n"," 30      30    NaN     deepskyblue           #00BFFF        rgb(0,191,255)\n"," 31      31    NaN  lightsteelblue           #B0C4DE      rgb(176,196,222)\n"," 32      32    NaN      dodgerblue           #1E90FF       rgb(30,144,255)]"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","tables = pd.read_html(url)\n","tables"]},{"cell_type":"markdown","id":"ed8eb3af-38d9-47f9-8dea-da02c65f453d","metadata":{},"source":["`tables` is now a list of dataframes representing the tables from the web page, in the sequence of their appearance. In the current  URL, there is only a single table, so the same can be accessed as shown below.\n"]},{"cell_type":"code","execution_count":113,"id":"2e1e6f4d-dc23-4b9f-9012-d78843d6e76a","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Number</td>\n","      <td>Color</td>\n","      <td>Color Name</td>\n","      <td>Hex Code #RRGGBB</td>\n","      <td>Decimal Code (R,G,B)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>lightsalmon</td>\n","      <td>#FFA07A</td>\n","      <td>rgb(255,160,122)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>salmon</td>\n","      <td>#FA8072</td>\n","      <td>rgb(250,128,114)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>darksalmon</td>\n","      <td>#E9967A</td>\n","      <td>rgb(233,150,122)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>lightcoral</td>\n","      <td>#F08080</td>\n","      <td>rgb(240,128,128)</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>coral</td>\n","      <td>#FF7F50</td>\n","      <td>rgb(255,127,80)</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>tomato</td>\n","      <td>#FF6347</td>\n","      <td>rgb(255,99,71)</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>orangered</td>\n","      <td>#FF4500</td>\n","      <td>rgb(255,69,0)</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>NaN</td>\n","      <td>gold</td>\n","      <td>#FFD700</td>\n","      <td>rgb(255,215,0)</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>orange</td>\n","      <td>#FFA500</td>\n","      <td>rgb(255,165,0)</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>NaN</td>\n","      <td>darkorange</td>\n","      <td>#FF8C00</td>\n","      <td>rgb(255,140,0)</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>lightyellow</td>\n","      <td>#FFFFE0</td>\n","      <td>rgb(255,255,224)</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>NaN</td>\n","      <td>lemonchiffon</td>\n","      <td>#FFFACD</td>\n","      <td>rgb(255,250,205)</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>NaN</td>\n","      <td>papayawhip</td>\n","      <td>#FFEFD5</td>\n","      <td>rgb(255,239,213)</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>NaN</td>\n","      <td>moccasin</td>\n","      <td>#FFE4B5</td>\n","      <td>rgb(255,228,181)</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>NaN</td>\n","      <td>peachpuff</td>\n","      <td>#FFDAB9</td>\n","      <td>rgb(255,218,185)</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>NaN</td>\n","      <td>palegoldenrod</td>\n","      <td>#EEE8AA</td>\n","      <td>rgb(238,232,170)</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>NaN</td>\n","      <td>khaki</td>\n","      <td>#F0E68C</td>\n","      <td>rgb(240,230,140)</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>NaN</td>\n","      <td>darkkhaki</td>\n","      <td>#BDB76B</td>\n","      <td>rgb(189,183,107)</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>NaN</td>\n","      <td>yellow</td>\n","      <td>#FFFF00</td>\n","      <td>rgb(255,255,0)</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>NaN</td>\n","      <td>lawngreen</td>\n","      <td>#7CFC00</td>\n","      <td>rgb(124,252,0)</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>NaN</td>\n","      <td>chartreuse</td>\n","      <td>#7FFF00</td>\n","      <td>rgb(127,255,0)</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>NaN</td>\n","      <td>limegreen</td>\n","      <td>#32CD32</td>\n","      <td>rgb(50,205,50)</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>NaN</td>\n","      <td>lime</td>\n","      <td>#00FF00</td>\n","      <td>rgb(0.255.0)</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>NaN</td>\n","      <td>forestgreen</td>\n","      <td>#228B22</td>\n","      <td>rgb(34,139,34)</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>NaN</td>\n","      <td>green</td>\n","      <td>#008000</td>\n","      <td>rgb(0,128,0)</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>NaN</td>\n","      <td>powderblue</td>\n","      <td>#B0E0E6</td>\n","      <td>rgb(176,224,230)</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>NaN</td>\n","      <td>lightblue</td>\n","      <td>#ADD8E6</td>\n","      <td>rgb(173,216,230)</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>28</td>\n","      <td>NaN</td>\n","      <td>lightskyblue</td>\n","      <td>#87CEFA</td>\n","      <td>rgb(135,206,250)</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>NaN</td>\n","      <td>skyblue</td>\n","      <td>#87CEEB</td>\n","      <td>rgb(135,206,235)</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>30</td>\n","      <td>NaN</td>\n","      <td>deepskyblue</td>\n","      <td>#00BFFF</td>\n","      <td>rgb(0,191,255)</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>31</td>\n","      <td>NaN</td>\n","      <td>lightsteelblue</td>\n","      <td>#B0C4DE</td>\n","      <td>rgb(176,196,222)</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>NaN</td>\n","      <td>dodgerblue</td>\n","      <td>#1E90FF</td>\n","      <td>rgb(30,144,255)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         0      1               2                 3                     4\n","0   Number  Color      Color Name  Hex Code #RRGGBB  Decimal Code (R,G,B)\n","1        1    NaN     lightsalmon           #FFA07A      rgb(255,160,122)\n","2        2    NaN          salmon           #FA8072      rgb(250,128,114)\n","3        3    NaN      darksalmon           #E9967A      rgb(233,150,122)\n","4        4    NaN      lightcoral           #F08080      rgb(240,128,128)\n","5        5    NaN           coral           #FF7F50       rgb(255,127,80)\n","6        6    NaN          tomato           #FF6347        rgb(255,99,71)\n","7        7    NaN       orangered           #FF4500         rgb(255,69,0)\n","8        8    NaN            gold           #FFD700        rgb(255,215,0)\n","9        9    NaN          orange           #FFA500        rgb(255,165,0)\n","10      10    NaN      darkorange           #FF8C00        rgb(255,140,0)\n","11      11    NaN     lightyellow           #FFFFE0      rgb(255,255,224)\n","12      12    NaN    lemonchiffon           #FFFACD      rgb(255,250,205)\n","13      13    NaN      papayawhip           #FFEFD5      rgb(255,239,213)\n","14      14    NaN        moccasin           #FFE4B5      rgb(255,228,181)\n","15      15    NaN       peachpuff           #FFDAB9      rgb(255,218,185)\n","16      16    NaN   palegoldenrod           #EEE8AA      rgb(238,232,170)\n","17      17    NaN           khaki           #F0E68C      rgb(240,230,140)\n","18      18    NaN       darkkhaki           #BDB76B      rgb(189,183,107)\n","19      19    NaN          yellow           #FFFF00        rgb(255,255,0)\n","20      20    NaN       lawngreen           #7CFC00        rgb(124,252,0)\n","21      21    NaN      chartreuse           #7FFF00        rgb(127,255,0)\n","22      22    NaN       limegreen           #32CD32        rgb(50,205,50)\n","23      23    NaN            lime           #00FF00          rgb(0.255.0)\n","24      24    NaN     forestgreen           #228B22        rgb(34,139,34)\n","25      25    NaN           green           #008000          rgb(0,128,0)\n","26      26    NaN      powderblue           #B0E0E6      rgb(176,224,230)\n","27      27    NaN       lightblue           #ADD8E6      rgb(173,216,230)\n","28      28    NaN    lightskyblue           #87CEFA      rgb(135,206,250)\n","29      29    NaN         skyblue           #87CEEB      rgb(135,206,235)\n","30      30    NaN     deepskyblue           #00BFFF        rgb(0,191,255)\n","31      31    NaN  lightsteelblue           #B0C4DE      rgb(176,196,222)\n","32      32    NaN      dodgerblue           #1E90FF       rgb(30,144,255)"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["tables[0]"]}],"metadata":{"kernelspec":{"display_name":"data-science","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
